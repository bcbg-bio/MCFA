{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "613b54bc-0eb6-42ee-9c45-2801cbee106a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import micca_model\n",
    "import simulate_model_gaussian\n",
    "torch.set_printoptions(linewidth = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f5b9837-402c-4e13-b34d-5c2b18e5adb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sqrtm(X):\n",
    "    U, l, VT = torch.linalg.svd(X)\n",
    "    return((U * torch.sqrt(l)) @ VT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b3ac4c2-ec1c-4978-8484-dceddfd7afdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "p = [3, 3]\n",
    "psum = np.concatenate([[0], np.cumsum(p, 0)]) \n",
    "d = 2\n",
    "k = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b72deda-d834-413c-8e87-2842904b8fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = simulate_model_gaussian.generate_model(p, k, d)\n",
    "data = model.simulate(n)\n",
    "Y_all = torch.cat(data.Y, dim = 1)\n",
    "Y_all = Y_all - torch.mean(Y_all, 0)\n",
    "Sigma_tilde = (Y_all.T @ Y_all) / (n - 1)\n",
    "W = torch.cat(model.W, dim = 1)\n",
    "Phi = torch.block_diag(*model.Phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a787b1e5-a383-4f07-8b03-57e95bd8218b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = [Y_m - torch.mean(Y_m, 0) for Y_m in data.Y]\n",
    "S11 = (Y[0].T @ Y[0])/(n-1)\n",
    "S22 = (Y[1].T @ Y[1])/(n-1)\n",
    "S12 = (Y[0].T @ Y[1])/(n-1)\n",
    "S11_inv2 = sqrtm(torch.linalg.pinv(S11, rcond = 1e-06))\n",
    "S22_inv2 = sqrtm(torch.linalg.pinv(S22, rcond = 1e-06))\n",
    "C12_tilde = S11_inv2 @ S12 @ S22_inv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e01bf385-3651-4cd8-b698-112af691511f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4583, 0.2244])\n",
      "tensor([0.4583])\n",
      "tensor([0.2244])\n"
     ]
    }
   ],
   "source": [
    "# Fit 2-D once, then 1-D twice with classic CCA\n",
    "F1, F2, rho, V1, V2 = micca_model.cca(Y[0], Y[1], d)\n",
    "print(rho)\n",
    "\n",
    "f1_1, f2_1, rho_1, a1_1, a2_1 = micca_model.cca(Y[0], Y[1], 1)\n",
    "print(rho_1)\n",
    "\n",
    "P1 = torch.eye(3) - f1_1 @ f1_1.T @ S11\n",
    "P2 = torch.eye(3) - f2_1 @ f2_1.T @ S22\n",
    "Y_mod = [Y[0] @ P1, Y[1] @ P2]\n",
    "Y_mod = [Y - torch.mean(Y, 0) for Y in Y_mod]\n",
    "\n",
    "f1_2, f2_2, rho_2, a1_2, a2_2 = micca_model.cca(Y_mod[0], Y_mod[1], 1, center = True)\n",
    "print(rho_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c11d736-10f5-47be-832f-17326a1ef579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6.7842e-01, 5.8495e-01, 9.1917e-09])\n",
      "tensor([6.7842e-01, 2.0567e-08, 1.4283e-08])\n",
      "tensor([5.8495e-01, 2.2308e-08, 3.1802e-09])\n"
     ]
    }
   ],
   "source": [
    "# Now once again, with ML solution implementation\n",
    "# Fit 2-d once\n",
    "W_hat, Phi_hat = micca_model.find_ML_params(Y, d = 2)\n",
    "W1 = W_hat[:, psum[0]:psum[1]]\n",
    "W2 = W_hat[:, psum[1]:psum[2]]\n",
    "\n",
    "print(torch.linalg.svd(S11_inv2 @ W1.T @ W2 @ S22_inv2).S[psum[0]:psum[1]])\n",
    "\n",
    "# Fit 1-d one time\n",
    "W_hat, Phi_hat = micca_model.find_ML_params(Y, d = 1)\n",
    "W1 = W_hat[:, psum[0]:psum[1]]\n",
    "W2 = W_hat[:, psum[1]:psum[2]]\n",
    "print(torch.linalg.svd(S11_inv2 @ W1.T @ W2 @ S22_inv2).S[psum[0]:psum[1]])\n",
    "\n",
    "# Project out learned space and fit again\n",
    "W1_tilde = W1 @ S11_inv2\n",
    "W2_tilde = W2 @ S22_inv2\n",
    "a1 = (W1_tilde / torch.sqrt(torch.sum(W1_tilde**2))).T\n",
    "a2 = (W2_tilde / torch.sqrt(torch.sum(W2_tilde**2))).T\n",
    "f1 = S11_inv2 @ a1\n",
    "f2 = S22_inv2 @ a2\n",
    "P1 = torch.eye(3) - f1 @ f1.T @ S11\n",
    "P2 = torch.eye(3) - f2 @ f2.T @ S22\n",
    "\n",
    "Y_mod = [Y[0] @ P1, Y[1] @ P2]\n",
    "Y_mod = [Y - torch.mean(Y, 0) for Y in Y_mod]\n",
    "S11_mod = (Y_mod[0].T @ Y_mod[0])/(n-1)\n",
    "S22_mod = (Y_mod[1].T @ Y_mod[1])/(n-1)\n",
    "S11_inv2_mod = sqrtm(torch.linalg.pinv(S11_mod, rcond = 1e-06))\n",
    "S22_inv2_mod = sqrtm(torch.linalg.pinv(S22_mod, rcond = 1e-06))\n",
    "\n",
    "W_hat, Phi_hat = micca_model.find_ML_params(Y_mod, d = 1)\n",
    "W1 = W_hat[:, psum[0]:psum[1]]\n",
    "W2 = W_hat[:, psum[1]:psum[2]]\n",
    "print(torch.linalg.svd(S11_inv2_mod @ W1.T @ W2 @ S22_inv2_mod).S[psum[0]:psum[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "870493b8-802e-4fcb-9484-9af186f23795",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(16.6310) tensor(7.8043)\n",
      "tensor(8.1300e-09) tensor(9.2266e-08)\n",
      "tensor(7.4895e-09) tensor(8.4254e-08)\n",
      "tensor(6.7699e-09) tensor(7.5840e-08)\n",
      "tensor(6.2095e-09) tensor(6.8909e-08)\n",
      "tensor(5.6104e-09) tensor(6.1765e-08)\n",
      "tensor(5.1432e-09) tensor(5.6644e-08)\n",
      "tensor(4.6462e-09) tensor(5.0534e-08)\n",
      "tensor(4.2337e-09) tensor(4.5463e-08)\n",
      "tensor(3.8241e-09) tensor(4.0933e-08)\n",
      "tensor(3.5010e-09) tensor(3.7483e-08)\n",
      "tensor(3.1439e-09) tensor(3.3311e-08)\n",
      "tensor(2.8554e-09) tensor(2.9791e-08)\n",
      "tensor(2.5526e-09) tensor(2.6765e-08)\n",
      "tensor(2.3080e-09) tensor(2.3909e-08)\n",
      "tensor(2.1134e-09) tensor(2.1839e-08)\n",
      "tensor(1.9130e-09) tensor(1.9374e-08)\n",
      "tensor(1.6929e-09) tensor(1.7092e-08)\n",
      "tensor(1.5341e-09) tensor(1.5416e-08)\n",
      "tensor(1.3659e-09) tensor(1.3462e-08)\n",
      "tensor(1.2380e-09) tensor(1.2171e-08)\n",
      "tensor(1.1179e-09) tensor(1.0958e-08)\n",
      "tensor(1.0108e-09) tensor(9.8219e-09)\n",
      "tensor(8.9793e-10) tensor(8.6321e-09)\n",
      "tensor(8.1482e-10) tensor(7.6177e-09)\n",
      "tensor([6.7826e-01, 5.8480e-01, 3.0529e-08])\n",
      "tensor(1.6667) tensor(25.0596)\n",
      "tensor(3.7905e-07) tensor(3.5023e-06)\n",
      "tensor(1.2183e-08) tensor(1.8209e-07)\n",
      "tensor(1.1070e-08) tensor(1.6621e-07)\n",
      "tensor(1.0333e-08) tensor(1.5545e-07)\n",
      "tensor(9.5757e-09) tensor(1.4408e-07)\n",
      "tensor(8.8323e-09) tensor(1.3300e-07)\n",
      "tensor(8.1887e-09) tensor(1.2352e-07)\n",
      "tensor(7.4206e-09) tensor(1.1218e-07)\n",
      "tensor(6.7845e-09) tensor(1.0247e-07)\n",
      "tensor(6.2399e-09) tensor(9.4592e-08)\n",
      "tensor(5.6910e-09) tensor(8.6315e-08)\n",
      "tensor(5.1769e-09) tensor(7.8662e-08)\n",
      "tensor(4.6275e-09) tensor(7.0317e-08)\n",
      "tensor(4.1620e-09) tensor(6.3332e-08)\n",
      "tensor(3.7636e-09) tensor(5.7426e-08)\n",
      "tensor(3.3550e-09) tensor(5.1321e-08)\n",
      "tensor(3.0123e-09) tensor(4.5975e-08)\n",
      "tensor(2.7324e-09) tensor(4.1789e-08)\n",
      "tensor(2.4372e-09) tensor(3.7422e-08)\n",
      "tensor(2.1805e-09) tensor(3.3356e-08)\n",
      "tensor(1.9555e-09) tensor(3.0053e-08)\n",
      "tensor(1.7322e-09) tensor(2.6662e-08)\n",
      "tensor(1.5400e-09) tensor(2.3697e-08)\n",
      "tensor(1.3785e-09) tensor(2.1270e-08)\n",
      "tensor([6.7826e-01, 4.4051e-08, 7.4909e-09])\n",
      "tensor(3.3459) tensor(6.1057)\n",
      "tensor(5.5971e-09) tensor(4.4620e-08)\n",
      "tensor(5.3741e-09) tensor(4.2440e-08)\n",
      "tensor(5.1310e-09) tensor(4.0057e-08)\n",
      "tensor(4.8456e-09) tensor(3.7874e-08)\n",
      "tensor(4.6122e-09) tensor(3.5273e-08)\n",
      "tensor(4.3632e-09) tensor(3.3145e-08)\n",
      "tensor(4.0841e-09) tensor(3.0661e-08)\n",
      "tensor(3.8165e-09) tensor(2.8503e-08)\n",
      "tensor(3.6239e-09) tensor(2.6806e-08)\n",
      "tensor(3.3529e-09) tensor(2.4690e-08)\n",
      "tensor(3.1553e-09) tensor(2.2935e-08)\n",
      "tensor(2.9434e-09) tensor(2.1384e-08)\n",
      "tensor(2.7568e-09) tensor(1.9759e-08)\n",
      "tensor(2.5354e-09) tensor(1.8177e-08)\n",
      "tensor(2.3137e-09) tensor(1.6480e-08)\n",
      "tensor(2.3399e-09) tensor(1.6354e-08)\n",
      "tensor(2.0236e-09) tensor(1.4262e-08)\n",
      "tensor(1.9111e-09) tensor(1.3359e-08)\n",
      "tensor(1.7149e-09) tensor(1.1896e-08)\n",
      "tensor(1.5666e-09) tensor(1.0808e-08)\n",
      "tensor(1.4521e-09) tensor(9.9750e-09)\n",
      "tensor(1.3450e-09) tensor(9.1615e-09)\n",
      "tensor(1.2217e-09) tensor(8.2176e-09)\n",
      "tensor(1.1282e-09) tensor(7.5900e-09)\n",
      "tensor([5.8481e-01, 1.3393e-08, 4.2334e-09])\n"
     ]
    }
   ],
   "source": [
    "# One more time with EM\n",
    "\n",
    "# Fit 2-D once\n",
    "std_normal = torch.distributions.Normal(0, 1)\n",
    "W_curr = std_normal.sample([2, sum(p)])\n",
    "Phi_curr = torch.eye(sum(p))\n",
    "for i in range(2500):\n",
    "    W_next, Phi_next = micca_model.EM_step_stable(W_curr, Phi_curr, Y_all, Sigma_tilde, p = p)\n",
    "    delta_W = torch.sum((W_curr - W_next)**2)\n",
    "    delta_Phi = torch.sum((Phi_curr - Phi_next)**2)\n",
    "    W_curr = W_next\n",
    "    Phi_curr = Phi_next\n",
    "    if (i%100 == 0): print(delta_W, delta_Phi)\n",
    "W_hat = W_curr\n",
    "Phi_hat = Phi_curr\n",
    "W1 = W_hat[:, psum[0]:psum[1]]\n",
    "W2 = W_hat[:, psum[1]:psum[2]]\n",
    "print(torch.linalg.svd(S11_inv2 @ W1.T @ W2 @ S22_inv2).S[psum[0]:psum[1]])\n",
    "\n",
    "# Fit 1-D once\n",
    "std_normal = torch.distributions.Normal(0, 1)\n",
    "W_curr = std_normal.sample([1, sum(p)])\n",
    "Phi_curr = torch.eye(sum(p))\n",
    "for i in range(2500):\n",
    "    W_next, Phi_next = micca_model.EM_step_stable(W_curr, Phi_curr, Y_all, Sigma_tilde, p = p)\n",
    "    delta_W = torch.sum((W_curr - W_next)**2)\n",
    "    delta_Phi = torch.sum((Phi_curr - Phi_next)**2)\n",
    "    W_curr = W_next\n",
    "    Phi_curr = Phi_next\n",
    "    if (i%100 == 0): print(delta_W, delta_Phi)\n",
    "W_hat = W_curr\n",
    "Phi_hat = Phi_curr\n",
    "W1 = W_hat[:, psum[0]:psum[1]]\n",
    "W2 = W_hat[:, psum[1]:psum[2]]\n",
    "print(torch.linalg.svd(S11_inv2 @ W1.T @ W2 @ S22_inv2).S[psum[0]:psum[1]])\n",
    "\n",
    "# Project out learned space and fit again\n",
    "W1_tilde = W1 @ S11_inv2\n",
    "W2_tilde = W2 @ S22_inv2\n",
    "a1 = (W1_tilde / torch.sqrt(torch.sum(W1_tilde**2))).T\n",
    "a2 = (W2_tilde / torch.sqrt(torch.sum(W2_tilde**2))).T\n",
    "f1_1 = S11_inv2 @ a1\n",
    "f2_1 = S22_inv2 @ a2\n",
    "P1 = torch.eye(3) - f1_1 @ f1_1.T @ S11\n",
    "P2 = torch.eye(3) - f2_1 @ f2_1.T @ S22\n",
    "Y_mod = [Y[0] @ P1, Y[1] @ P2]\n",
    "Y_mod = [Y - torch.mean(Y, 0) for Y in Y_mod]\n",
    "Y_mod_all = torch.cat(Y_mod, dim = 1)\n",
    "S11_mod = (Y_mod[0].T @ Y_mod[0])/(n-1)\n",
    "S12_mod = (Y_mod[0].T @ Y_mod[1])/(n-1)\n",
    "S22_mod = (Y_mod[1].T @ Y_mod[1])/(n-1)\n",
    "S11_inv2_mod = sqrtm(torch.linalg.pinv(S11_mod, rcond = 1e-06))\n",
    "S22_inv2_mod = sqrtm(torch.linalg.pinv(S22_mod, rcond = 1e-06))\n",
    "Sigma_tilde_mod = torch.cat([torch.cat([S11_mod, S12_mod], 1), torch.cat([S12_mod.T, S22_mod], 1)], 0)\n",
    "\n",
    "std_normal = torch.distributions.Normal(0, 1)\n",
    "W_curr = std_normal.sample([1, sum(p)])\n",
    "Phi_curr = torch.eye(sum(p))\n",
    "for i in range(2500):\n",
    "    W_next, Phi_next = micca_model.EM_step_stable(W_curr, Phi_curr, Y_mod_all, Sigma_tilde_mod, p = p)\n",
    "    delta_W = torch.sum((W_curr - W_next)**2)\n",
    "    delta_Phi = torch.sum((Phi_curr - Phi_next)**2)\n",
    "    W_curr = W_next\n",
    "    Phi_curr = Phi_next\n",
    "    if (i%100 == 0): print(delta_W, delta_Phi)\n",
    "W_hat = W_curr\n",
    "Phi_hat = Phi_curr\n",
    "W1 = W_hat[:, psum[0]:psum[1]]\n",
    "W2 = W_hat[:, psum[1]:psum[2]]\n",
    "W1_tilde = W1 @ S11_inv2_mod\n",
    "W2_tilde = W2 @ S22_inv2_mod\n",
    "a1 = (W1_tilde / torch.sqrt(torch.sum(W1_tilde**2))).T\n",
    "a2 = (W2_tilde / torch.sqrt(torch.sum(W2_tilde**2))).T\n",
    "f1_2 = S11_inv2_mod @ a1\n",
    "f2_2 = S22_inv2_mod @ a2\n",
    "print(torch.linalg.svd(S11_inv2_mod @ W1.T @ W2 @ S22_inv2_mod).S[psum[0]:psum[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85541859-d11e-4800-98cb-a8afd366d32b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0781]])\n",
      "tensor([[1.2029]])\n",
      "tensor([[1.]])\n",
      "tensor([[1.0000]])\n"
     ]
    }
   ],
   "source": [
    "print(f1_2.T @ S11 @ f1_2)\n",
    "print(f2_2.T @ S22 @ f2_2)\n",
    "print(f1_2.T @ S11_mod @ f1_2)\n",
    "print(f2_2.T @ S22_mod @ f2_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "362ec94a-67a1-49a9-845a-294a8ecf0495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1082,  0.4640],\n",
       "        [-0.3541,  0.0287],\n",
       "        [ 0.0775,  0.4144]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c53aab41-fc25-4c26-b1a9-21aeee6fd355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4110],\n",
       "        [0.2049],\n",
       "        [0.3765]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78e9b32a-aa3f-49c0-bbdc-2b7019a1ef60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.1860) tensor(55.0333) tensor(12085.7266)\n",
      "tensor(1.4777e-07) tensor(6.0834e-07) tensor(11336.6396)\n",
      "tensor(1.7205e-11) tensor(6.2288e-11) tensor(11336.6367)\n",
      "tensor(5.4073e-13) tensor(7.8693e-13) tensor(11336.6367)\n",
      "tensor(1.1653e-12) tensor(7.8906e-12) tensor(11336.6367)\n",
      "tensor(2.2307e-12) tensor(4.7669e-12) tensor(11336.6357)\n",
      "tensor(7.1410e-13) tensor(9.8694e-12) tensor(11336.6367)\n",
      "tensor(1.4924e-12) tensor(1.9655e-12) tensor(11336.6377)\n",
      "tensor(8.4133e-13) tensor(1.3185e-11) tensor(11336.6377)\n",
      "tensor(1.1042e-12) tensor(9.0008e-12) tensor(11336.6367)\n",
      "tensor(8.0475e-13) tensor(1.4913e-11) tensor(11336.6367)\n",
      "tensor(2.4394e-12) tensor(4.2011e-12) tensor(11336.6377)\n",
      "tensor(2.6810e-12) tensor(4.8077e-12) tensor(11336.6367)\n",
      "tensor(1.2372e-12) tensor(3.1566e-12) tensor(11336.6377)\n",
      "tensor(6.4287e-13) tensor(4.0128e-12) tensor(11336.6377)\n",
      "tensor(1.4860e-12) tensor(1.1475e-12) tensor(11336.6377)\n",
      "tensor(7.6300e-13) tensor(9.9520e-12) tensor(11336.6367)\n",
      "tensor(1.0927e-12) tensor(7.2564e-13) tensor(11336.6367)\n",
      "tensor(3.2814e-12) tensor(1.2550e-12) tensor(11336.6377)\n",
      "tensor(1.7293e-12) tensor(2.9337e-12) tensor(11336.6367)\n",
      "tensor(9.0422e-13) tensor(3.5385e-12) tensor(11336.6367)\n",
      "tensor(1.4838e-12) tensor(4.3725e-12) tensor(11336.6367)\n",
      "tensor(3.5622e-13) tensor(2.7409e-12) tensor(11336.6367)\n",
      "tensor(1.4337e-12) tensor(3.2170e-12) tensor(11336.6367)\n",
      "tensor(3.2954e-12) tensor(1.0952e-11) tensor(11336.6367)\n",
      "tensor(2.0327e-12) tensor(9.4742e-12) tensor(11336.6367)\n",
      "tensor(7.6494e-13) tensor(7.7272e-12) tensor(11336.6367)\n",
      "tensor(1.8480e-13) tensor(3.0189e-12) tensor(11336.6367)\n",
      "tensor(5.6666e-13) tensor(8.3196e-12) tensor(11336.6377)\n",
      "tensor(5.4007e-13) tensor(1.6787e-12) tensor(11336.6367)\n",
      "tensor(4.5391e-13) tensor(1.2932e-12) tensor(11336.6367)\n",
      "tensor(9.8016e-13) tensor(2.6974e-12) tensor(11336.6367)\n",
      "tensor(1.8761e-12) tensor(1.5126e-12) tensor(11336.6377)\n",
      "tensor(1.1272e-12) tensor(1.0629e-11) tensor(11336.6377)\n",
      "tensor(1.7338e-12) tensor(8.8418e-12) tensor(11336.6367)\n",
      "tensor(4.2100e-13) tensor(5.8540e-12) tensor(11336.6357)\n",
      "tensor(2.5713e-13) tensor(7.8337e-13) tensor(11336.6377)\n",
      "tensor(1.3616e-12) tensor(5.8149e-12) tensor(11336.6377)\n",
      "tensor(3.8569e-13) tensor(1.9744e-12) tensor(11336.6367)\n",
      "tensor(1.1462e-12) tensor(1.8341e-12) tensor(11336.6367)\n",
      "tensor(8.5998e-13) tensor(7.3985e-12) tensor(11336.6367)\n",
      "tensor(2.2107e-12) tensor(4.2988e-12) tensor(11336.6367)\n",
      "tensor(1.7626e-12) tensor(8.3409e-12) tensor(11336.6367)\n",
      "tensor(1.2937e-12) tensor(1.9732e-11) tensor(11336.6377)\n",
      "tensor(1.8796e-12) tensor(5.9828e-12) tensor(11336.6367)\n",
      "tensor(5.2497e-13) tensor(2.7489e-12) tensor(11336.6367)\n",
      "tensor(3.1780e-12) tensor(1.0647e-11) tensor(11336.6377)\n",
      "tensor(1.6530e-12) tensor(1.4149e-12) tensor(11336.6367)\n",
      "tensor(6.4065e-13) tensor(9.8019e-12) tensor(11336.6377)\n",
      "tensor(7.4568e-13) tensor(1.5126e-12) tensor(11336.6367)\n",
      "tensor(11336.6367)\n",
      "tensor(11336.6367)\n"
     ]
    }
   ],
   "source": [
    "# Testing the conjecture with two datasets\n",
    "\n",
    "# Fit model with EM\n",
    "std_normal = torch.distributions.Normal(0, 1)\n",
    "W_curr = std_normal.sample([d, sum(p)])\n",
    "Phi_curr = torch.eye(sum(p))\n",
    "for i in range(5000):\n",
    "    # W_next, Phi_next = micca_model.EM_step_stable(W_curr, Phi_curr, Y_all, Sigma_tilde, p = p)\n",
    "    W_next, Phi_next = micca_model.EM_step(W_curr, Phi_curr, Sigma_tilde, p = p)\n",
    "    delta_W = torch.sum((W_curr - W_next)**2)\n",
    "    delta_Phi = torch.sum((Phi_curr - Phi_next)**2)\n",
    "    W_curr = W_next\n",
    "    Phi_curr = Phi_next\n",
    "    if (i%100 == 0): print(delta_W, delta_Phi, micca_model.loglik(W_curr.T @ W_curr + Phi_curr, Sigma_tilde, n))\n",
    "W_em = W_curr\n",
    "Phi_em = Phi_curr\n",
    "print(micca_model.loglik(W_em.T @ W_em + Phi_em, Sigma_tilde, n))\n",
    "\n",
    "W_ml, Phi_ml = micca_model.find_ML_params(Y, d = 2)\n",
    "print(micca_model.loglik(W_ml.T @ W_ml + Phi_ml, Sigma_tilde, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e968ffdf-7ff6-4ef3-9e2c-29d78186b20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11336.6367)\n",
      "tensor(11336.6377)\n",
      "tensor(11336.6367)\n"
     ]
    }
   ],
   "source": [
    "# The original conjecture in terms of SVD of W_tilde\n",
    "W1 = W_em[:, psum[0]:psum[1]]\n",
    "W2 = W_em[:, psum[1]:psum[2]]\n",
    "W1_tilde = W1 @ S11_inv2\n",
    "W2_tilde = W2 @ S22_inv2\n",
    "\n",
    "_, S1, A1T = torch.linalg.svd(W1_tilde, full_matrices=False)\n",
    "_, S2, A2T = torch.linalg.svd(W2_tilde, full_matrices=False)\n",
    "F1 = S11_inv2 @ A1T.T\n",
    "F2 = S22_inv2 @ A2T.T\n",
    "\n",
    "model_cov_1 = torch.cat([torch.cat([S11, W1.T @ W2], axis = 1),\n",
    "                         torch.cat([W2.T @ W1, S22], axis = 1)], axis = 0)\n",
    "model_cov_2 = torch.cat([torch.cat([torch.eye(p[0]), W1_tilde.T @ W2_tilde], axis = 1),\n",
    "                         torch.cat([W2_tilde.T @ W1_tilde, torch.eye(p[1])], axis = 1)], axis = 0)\n",
    "gen_var = torch.cat([torch.cat([F1.T @ S11 @ F1, F1.T @ S12 @ F2], axis = 1),\n",
    "                         torch.cat([(F1.T @ S12 @ F2).T, F2.T @ S22 @ F2], axis = 1)], axis = 0)\n",
    "gen_var_2 = torch.cat([torch.cat([torch.eye(p[0]), A1T.T @ F1.T @ S12 @ F2 @ A2T], axis = 1),\n",
    "                         torch.cat([(A1T.T @ F1.T @ S12 @ F2 @ A2T).T, torch.eye(p[1])], axis = 1)], axis = 0)\n",
    "D_half = torch.block_diag(sqrtm(S11), sqrtm(S22))\n",
    "\n",
    "Sigma_alt = D_half @ gen_var_2 @ D_half\n",
    "print(micca_model.loglik(model_cov_1, Sigma_tilde, n))\n",
    "print(micca_model.loglik(Sigma_alt, Sigma_tilde, n))\n",
    "print(micca_model.loglik(W_ml.T @ W_ml + Phi_ml, Sigma_tilde, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "29d9ca8b-e37d-4c2d-96e8-09b175ce09b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10840.6182)\n"
     ]
    }
   ],
   "source": [
    "mat = F1.T @ S12 @ F2\n",
    "Um, Sm, VmT = torch.linalg.svd(mat)\n",
    "M1 = Um * torch.sqrt(Sm)\n",
    "M2 = VmT.T * torch.sqrt(Sm)\n",
    "W1_test =  S11 @ F1 @ M1\n",
    "W2_test =  S22 @ F2 @ M2\n",
    "Phi1_test = S11 - W1_test @ W1_test.T\n",
    "Phi2_test = S22 - W2_test @ W2_test.T\n",
    "W_test = torch.cat([W1_test, W2_test], axis = 0)\n",
    "Phi_test = torch.block_diag(Phi1_test, Phi2_test)\n",
    "Sigma_test = W_test @ W_test.T + Phi_test\n",
    "print(micca_model.loglik(Sigma_test, Sigma_tilde, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "726fda98-1187-4022-8e00-116a1a03cd04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.4565e-13) tensor(3.4497e-12) tensor(10840.6191)\n",
      "tensor(2.8880e-14) tensor(9.7167e-13) tensor(10840.6191)\n",
      "tensor(1.4211e-13) tensor(5.4468e-13) tensor(10840.6191)\n",
      "tensor(4.5519e-14) tensor(3.9924e-13) tensor(10840.6191)\n",
      "tensor(1.0981e-13) tensor(4.5031e-13) tensor(10840.6182)\n",
      "tensor(6.9778e-14) tensor(2.7467e-13) tensor(10840.6191)\n",
      "tensor(3.4098e-14) tensor(6.4415e-13) tensor(10840.6191)\n",
      "tensor(8.5501e-14) tensor(5.5156e-13) tensor(10840.6182)\n",
      "tensor(1.3368e-13) tensor(4.9849e-13) tensor(10840.6191)\n",
      "tensor(7.9992e-14) tensor(2.8266e-13) tensor(10840.6191)\n"
     ]
    }
   ],
   "source": [
    "W_curr = W_test.T\n",
    "Phi_curr = Phi_test.T\n",
    "for i in range(10):\n",
    "    # W_next, Phi_next = micca_model.EM_step_stable(W_curr, Phi_curr, Y_all, Sigma_tilde, p = p)\n",
    "    W_next, Phi_next = micca_model.EM_step(W_curr, Phi_curr, Sigma_tilde, p = p)\n",
    "    delta_W = torch.sum((W_curr - W_next)**2)\n",
    "    delta_Phi = torch.sum((Phi_curr - Phi_next)**2)\n",
    "    W_curr = W_next\n",
    "    Phi_curr = Phi_next\n",
    "    print(delta_W, delta_Phi, micca_model.loglik(W_curr.T @ W_curr + Phi_curr, Sigma_tilde, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b08dad82-8e49-4843-877f-8aa67a2836d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0368e-06,  2.7544e-07],\n",
       "        [ 7.3637e-07,  7.1142e-08],\n",
       "        [ 4.8321e-07,  1.6124e-07]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(C12_tilde - W1_tilde.T @ W2_tilde) @ W2_tilde.T @ torch.linalg.inv(1 - W2_tilde @ W2_tilde.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "527e3db6-1dc9-469a-a406-3be6cc2d9109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4559, -0.0409],\n",
       "        [ 0.0403,  0.2220]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1_ml = W_ml[:, psum[0]:psum[1]]\n",
    "W2_ml = W_ml[:, psum[1]:psum[2]]\n",
    "W1_ml_tilde = W1_ml @ S11_inv2\n",
    "W2_ml_tilde = W2_ml @ S22_inv2\n",
    "W1_ml_tilde.T @ W2_ml_tilde\n",
    "A1T @ W1_ml_tilde.T @ W2_ml_tilde @ A2T.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f6106560-9f9c-46b9-b2cd-478c06dffb7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4559, -0.0409],\n",
       "        [ 0.0403,  0.2220]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "M1 @ M2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f02fa61b-c20c-4c2f-986e-af0022287da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.5830)\n"
     ]
    }
   ],
   "source": [
    "# Re-write in terms of a sequence\n",
    "# Currently only d = 2\n",
    "# a1 = (W1_tilde.T/torch.sqrt(torch.sum(W1_tilde**2, 1)))\n",
    "# a2 = (W2_tilde.T/torch.sqrt(torch.sum(W2_tilde**2, 1)))\n",
    "# f1 = S11_inv2 @ a1\n",
    "# f2 = S22_inv2 @ a2\n",
    "\n",
    "# f1_1 = f1[:, 0:1]\n",
    "# f2_1 = f2[:, 0:1]\n",
    "# f1_2 = f1[:, 1:2]\n",
    "# f2_2 = f2[:, 1:2]\n",
    "\n",
    "f1_1 = F1[:, 0:1]\n",
    "f2_1 = F2[:, 0:1]\n",
    "f1_2 = F1[:, 1:2]\n",
    "f2_2 = F2[:, 1:2]\n",
    "\n",
    "P1 = torch.eye(p[0]) - f1_1 @ f1_1.T @ S11\n",
    "P2 = torch.eye(p[1]) - f2_1 @ f2_1.T @ S22\n",
    "Y_mod = [Y[0] @ P1, Y[1] @ P2]\n",
    "Y_mod = [Y - torch.mean(Y, 0) for Y in Y_mod]\n",
    "Y_mod_all = torch.cat(Y_mod, dim = 1)\n",
    "S11_mod = (Y_mod[0].T @ Y_mod[0])/(n-1)\n",
    "S12_mod = (Y_mod[0].T @ Y_mod[1])/(n-1)\n",
    "S22_mod = (Y_mod[1].T @ Y_mod[1])/(n-1)\n",
    "\n",
    "Phi_1 = torch.tensor([[f1_1.T @ S11 @ f1_1, f1_1.T @ S12 @ f2_1],\n",
    "                      [f1_1.T @ S12 @ f2_1, f2_1.T @ S22 @ f2_1]])\n",
    "Phi_2 = torch.tensor([[f1_2.T @ S11 @ f1_2, f1_2.T @ S12 @ f2_2],\n",
    "                      [f1_2.T @ S12 @ f2_2, f2_2.T @ S22 @ f2_2]])\n",
    "print(torch.logdet(Phi_1) + torch.logdet(Phi_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84e1afc1-bb8e-4acc-97b7-a27de678603b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([], size=(10, 0))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "453c8cc5-aa9f-4dbb-a06b-07289181d134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3551)\n"
     ]
    }
   ],
   "source": [
    "Phi_1 = torch.tensor([[f1_1.T @ S11 @ f1_1, f1_1.T @ S12 @ f2_1],\n",
    "                      [f1_1.T @ S12 @ f2_1, f2_1.T @ S22 @ f2_1]])\n",
    "Phi_2 = torch.tensor([[f1_2.T @ S11_mod @ f1_2, f1_2.T @ S12_mod @ f2_2],\n",
    "                      [f1_2.T @ S12_mod @ f2_2, f2_2.T @ S22_mod @ f2_2]])\n",
    "print(torch.linalg.det(Phi_1)*torch.linalg.det(Phi_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74e3a75e-5532-4390-a621-758d2ab6e6fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_2.T @ S11_mod @ f1_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065a6318-fb67-47c6-aa0e-20f7ba0ecbc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6fd887fc-2f21-423d-8341-695fb9d28f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.9802e-08,  2.9802e-08, -1.3784e-07],\n",
      "        [-1.4901e-08,  8.9407e-08,  5.4017e-08],\n",
      "        [-1.5460e-07,  5.4017e-08, -5.3644e-07]])\n",
      "tensor([[-0.0012,  0.0009,  0.0008],\n",
      "        [-0.0024,  0.0017,  0.0015],\n",
      "        [ 0.0018, -0.0013, -0.0012]])\n",
      "tensor([[-2.9802e-08, -6.7754e-08, -8.1956e-08],\n",
      "        [-7.3225e-08, -1.4901e-07, -3.3528e-08],\n",
      "        [-6.7055e-08, -2.9802e-08,  0.0000e+00]])\n",
      "tensor([[ 7.8357e-09, -3.2624e-08],\n",
      "        [-1.9469e-08,  8.6988e-08],\n",
      "        [ 3.8332e-08, -1.3337e-07],\n",
      "        [ 3.1983e-08,  6.8157e-09],\n",
      "        [-6.1283e-10, -4.6031e-08],\n",
      "        [-1.3562e-07, -3.9085e-08]])\n"
     ]
    }
   ],
   "source": [
    "# Stationary points of likelihood\n",
    "print((Sigma_inv - Sigma_inv @ Sigma_tilde @ Sigma_inv)[psum[0]:psum[1], psum[0]:psum[1]])\n",
    "print((Sigma_inv - Sigma_inv @ Sigma_tilde @ Sigma_inv)[psum[0]:psum[1], psum[1]:psum[2]])\n",
    "print((Sigma_inv - Sigma_inv @ Sigma_tilde @ Sigma_inv)[psum[1]:psum[2], psum[1]:psum[2]])\n",
    "print((Sigma_inv - Sigma_inv @ Sigma_tilde @ Sigma_inv)@ W_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5742aa88-a53b-482b-b2c9-e389e0115d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.7217, 3.6651, 3.5138, 1.9860, 1.5126, 1.0074])\n"
     ]
    }
   ],
   "source": [
    "# Lemma 1\n",
    "print(torch.linalg.svd(Sigma_tilde - W_hat @ W_hat.T).S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e42d0f65-03a3-4897-bc96-e938357682bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0000e+00,  1.7168e-08,  1.1194e-07,  6.4185e-03, -4.6447e-03,\n",
      "         -4.1118e-03],\n",
      "        [-5.0893e-08,  1.0000e+00, -5.1973e-08,  7.4838e-03, -5.4158e-03,\n",
      "         -4.7945e-03],\n",
      "        [ 1.7917e-07, -4.5378e-08,  1.0000e+00, -2.7382e-03,  1.9818e-03,\n",
      "          1.7546e-03],\n",
      "        [ 3.1021e-03,  6.1035e-03, -4.6053e-03,  1.0000e+00,  1.4080e-07,\n",
      "          3.7851e-08],\n",
      "        [-3.7459e-03, -7.3711e-03,  5.5631e-03,  2.8106e-07,  1.0000e+00,\n",
      "         -7.2488e-08],\n",
      "        [-2.1018e-03, -4.1363e-03,  3.1221e-03,  2.6460e-07,  2.1112e-07,\n",
      "          1.0000e+00]])\n",
      "tensor([[ 1.0000e+00, -8.5770e-08,  1.0978e-08,  6.4186e-03, -4.6447e-03,\n",
      "         -4.1117e-03],\n",
      "        [-1.1426e-08,  1.0000e+00, -7.3851e-09,  7.4838e-03, -5.4157e-03,\n",
      "         -4.7945e-03],\n",
      "        [ 9.6096e-08,  2.2991e-08,  1.0000e+00, -2.7381e-03,  1.9818e-03,\n",
      "          1.7546e-03],\n",
      "        [ 3.1023e-03,  6.1035e-03, -4.6052e-03,  1.0000e+00,  7.2222e-08,\n",
      "         -1.3094e-08],\n",
      "        [-3.7459e-03, -7.3710e-03,  5.5632e-03,  1.5173e-07,  1.0000e+00,\n",
      "         -8.1790e-08],\n",
      "        [-2.1015e-03, -4.1363e-03,  3.1227e-03, -2.2179e-08, -2.1048e-08,\n",
      "          1.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "# Lemma 2\n",
    "print((Sigma_tilde @ Sigma_inv)) # Identity on block diagonal\n",
    "print((Sigma_tilde - W_hat @ W_hat.T) @ Phi_inv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
