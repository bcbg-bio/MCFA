{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "simulate_inclusion_stats.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPgbcBnBE/EF0uAaefgiVeC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/collinwa/MPCCA/blob/model_refactor/analysis_notebooks/simulate_inclusion_stats.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yytNvF8OPFcE"
      },
      "source": [
        "import numpy as np                                                                                                                                                                                                 \n",
        "import pandas as pd                                                                                                                                                                                                \n",
        "import torch                                                                                                                                                                                                       \n",
        "import mpcca_collin.MPCCA.micca_model as micca\n",
        "import mpcca_collin.MPCCA.model as model                                                                                                                                                                   \n",
        "from typing import List\n",
        "from scipy import stats\n",
        "import seaborn as sns\n",
        "torch.set_printoptions(linewidth = 200)\n",
        "np.set_printoptions(linewidth = 200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0brJW2vjvQXo",
        "outputId": "ba048dc7-600d-4d83-d64c-ba32ef60b6a9"
      },
      "source": [
        "import importlib\n",
        "importlib.reload(micca)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'mpcca_collin.MPCCA.micca_model' from '/gpfs/commons/home/bbrown/mpcca_collin/MPCCA/micca_model.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTSdO-CUSBRm"
      },
      "source": [
        "def generate_dataset(n, d):\n",
        "  if lam is not None:\n",
        "    ecdf_lam = stats.gaussian_kde(lam)\n",
        "    lam_sample = torch.tensor(ecdf_lam.resample(len(lam))[0], dtype=torch.float)\n",
        "    if(n > d):\n",
        "      # TODO(brielin): can I just use the right SVs as V or are these not independent enough?\n",
        "      U = torch.linalg.svd(torch.randn(n, d), full_matrices=False).U\n",
        "      VT = torch.linalg.svd(torch.randn(d, d), full_matrices=False).Vh\n",
        "    else:\n",
        "      U = torch.linalg.svd(torch.randn(n, n), full_matrices=False).U\n",
        "      VT = torch.linalg.svd(torch.randn(n, d), full_matrices=False).Vh\n",
        "    X = U * lam_sample @ VT\n",
        "  else:\n",
        "    X = torch.randn(n, d)\n",
        "  return X\n",
        "\n",
        "def simulate_micca(n: int, d: List[int], k: List[int], p: int = 1, n_samples = 100):                                                                                                                                             \n",
        "    \"\"\"Calculates the MCCA (Parra) solution to random data.                                                                                                                                                        \n",
        "                                                                                                                                                                                                                   \n",
        "    Args:                                                                                                                                                                                                          \n",
        "        n: Integer. Sample size.                                                                                                                                                                                   \n",
        "        d: List of integers. Dimensions of the datasets to simulate.                                                                                                                                               \n",
        "        p: Integer. Number of shared components to remove before residual PCA.\n",
        "        lambda: List of torch tensors of length d. These are used to construct\n",
        "            simulated random matrix spectra.                                                                                                                                     \n",
        "    \"\"\"                                                                                                                                                                                                            \n",
        "    sim_res = np.empty((n_samples, 1 + len(d)))\n",
        "    for sample in range(n_samples):                                                                                                                                                                                \n",
        "        datasets = [torch.randn(n, di) for di in d]                                                                                                                                               \n",
        "        micca_res = micca.micca(datasets, c_shared=p, c_private=[1]*len(d), dimensions=k)                                                                                                                                        \n",
        "        iter_data = np.array([micca_res.rho.numpy()[0]] +                                                                                                                                                          \n",
        "                       [lam.numpy()[0] for lam in micca_res.lam_private])                                                                                                                                          \n",
        "        sim_res[sample, :] = iter_data                                                                                                                                                                                \n",
        "    sim_res = pd.DataFrame(                                                                                                                                                                                        \n",
        "        sim_res, columns = ['rho'] + ['lam'+str(i) for i in range(len(d))])                                                                                                                                        \n",
        "    return sim_res\n",
        "\n",
        "def simulate_em_latent(n: int, d: List[int], p: int = 1, n_samples = 100):                                                                                                                                             \n",
        "    \"\"\"Calculates the MPCCA (EM) solution to random data.                                                                                                                                                        \n",
        "                                                                                                                                                                                                                   \n",
        "    Args:                                                                                                                                                                                                          \n",
        "        n: Integer. Sample size.                                                                                                                                                                                   \n",
        "        d: List of integers. Dimensions of the datasets to simulate.                                                                                                                                               \n",
        "        p: Integer. Number of shared components to remove before residual PCA.                                                                                                                                     \n",
        "    \"\"\"                                                                                                                                                                                                            \n",
        "    sim_res = np.empty((n_samples, p))                                                                                                                                                                   \n",
        "    for sample in range(n_samples):                                                                                                                                                                                \n",
        "        datasets = [torch.tensor(np.random.normal(                                                                                                                                                                 \n",
        "            loc=0, scale=1, size=n*di).reshape((n,di))) for di in d]\n",
        "        y_concat = torch.cat(datasets, axis=1).double()\n",
        "        y_dims = torch.tensor(d)\n",
        "        x_dims = torch.tensor([2]*len(d))                                                                                                  \n",
        "        W_model, L_model, Phi_model = model.fit_model(y_dims, x_dims, datasets, p, y_concat, n, steps=500, toprint=100, method=\"stable\")\n",
        "        gen_vars, _ = micca.calc_feature_genvar(W_model.T, Phi_model)\n",
        "        print(min(gen_vars))\n",
        "        latent_data_list = [model.project_latent_individual(W_model, L_model, Phi_model, p, y_concat, x_dims, y_dims, i)[0] for i in range(len(d))]\n",
        "        rho, rb, rw = model.compute_ISC(latent_data_list)\n",
        "        print(max(rho))\n",
        "        iter_data = rho.numpy()                                                                                                                                        \n",
        "        sim_res[sample] = iter_data                                                                                                                                                                                \n",
        "    sim_res = pd.DataFrame(sim_res, columns=[\"rho_\" + str(i) for i in range(p)])\n",
        "    return sim_res\n",
        "\n",
        "def simulate_em_simple(n: int, d: List[int], p: int = 1, n_samples = 100):                                                                                                                                             \n",
        "    \"\"\"Calculates the MPCCA (EM) solution to random data.                                                                                                                                                        \n",
        "                                                                                                                                                                                                                   \n",
        "    Args:                                                                                                                                                                                                          \n",
        "        n: Integer. Sample size.                                                                                                                                                                                   \n",
        "        d: List of integers. Dimensions of the datasets to simulate.                                                                                                                                               \n",
        "        p: Integer. Number of shared components to remove before residual PCA.                                                                                                                                     \n",
        "    \"\"\"                                                                                                                                                                                                            \n",
        "    sim_res = np.empty((n_samples, p))                                                                                                                                                                   \n",
        "    for sample in range(n_samples):                                                                                                                                                                                \n",
        "        datasets = [torch.tensor(np.random.normal(                                                                                                                                                                 \n",
        "            loc=0, scale=1, size=n*di).reshape((n,di))) for di in d]                                                                                                                                           \n",
        "        W_model, Phi_model = micca.fit_EM(datasets, d=p, niter=500)\n",
        "        gen_vars, total = micca.calc_feature_genvar(W_model, Phi_model)\n",
        "        print(gen_vars)\n",
        "        print(total)\n",
        "        iter_data = gen_vars.numpy()                                                                                                                                        \n",
        "        sim_res[sample] = iter_data                                                                                                                                                                                \n",
        "    sim_res = pd.DataFrame(sim_res, columns=[\"gen_var_\" + str(i) for i in range(p)])\n",
        "    return sim_res\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLt--daraw2I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d921d16-f663-4899-ebb5-41183b135b16"
      },
      "source": [
        "n_samples = 1000\n",
        "n = 685\n",
        "d = [11, 33, 49, 66, 29] # [11, 20212, 136545, 6042, 1252]\n",
        "k = [11, 33, 49, 66, 29]\n",
        "sim_res = simulate_micca(n=685, d=d, p=15, k=k, n_samples=n_samples)\n",
        "print(sim_res)\n",
        "print(sim_res.mean())\n",
        "print(np.sqrt(sim_res.var()/n_samples))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          rho          lam0      lam1      lam2      lam3      lam4\n",
            "0    0.258698  1.035330e-15  1.139778  1.191013  1.258509  1.108794\n",
            "1    0.256040  1.322059e-15  1.136828  1.214310  1.247792  1.135921\n",
            "2    0.264354  1.432440e-15  1.117148  1.242487  1.295516  1.179863\n",
            "3    0.260046  1.415792e-15  1.124557  1.206862  1.250550  1.141029\n",
            "4    0.251159  1.454914e-15  1.115594  1.207076  1.231101  1.138084\n",
            "..        ...           ...       ...       ...       ...       ...\n",
            "995  0.253543  1.471786e-15  1.149174  1.196339  1.262490  1.114686\n",
            "996  0.253748  1.433331e-15  1.135883  1.182950  1.251257  1.095737\n",
            "997  0.253144  9.439523e-16  1.133157  1.191262  1.239744  1.108834\n",
            "998  0.271002  1.144244e-15  1.135903  1.196102  1.237651  1.124490\n",
            "999  0.262126  1.390974e-15  1.133492  1.188132  1.294842  1.104374\n",
            "\n",
            "[1000 rows x 6 columns]\n",
            "rho     2.534394e-01\n",
            "lam0    1.657319e-15\n",
            "lam1    1.139830e+00\n",
            "lam2    1.202078e+00\n",
            "lam3    1.253496e+00\n",
            "lam4    1.119363e+00\n",
            "dtype: float64\n",
            "rho     1.821399e-04\n",
            "lam0    3.453264e-17\n",
            "lam1    4.535160e-04\n",
            "lam2    4.384586e-04\n",
            "lam3    4.083553e-04\n",
            "lam4    4.748131e-04\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "0sKxcGh3j_5P",
        "outputId": "ab11b6ad-4fed-4601-b528-5ddc0b711d01"
      },
      "source": [
        "sns.histplot(data = sim_res, x = 'rho')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<AxesSubplot:xlabel='rho', ylabel='Count'>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5ONP9P44Im_",
        "outputId": "e20c71ba-552c-431a-9bec-091b6cb6cae9"
      },
      "source": [
        "n_samples = 1000\n",
        "n = 685\n",
        "d = [33, 49, 66, 29] # [11, 20212, 136545, 6042, 1252]\n",
        "k = [33, 49, 66, 29]\n",
        "sim_res = simulate_micca(n=685, d=d, p=15, k=k, n_samples=n_samples)\n",
        "print(sim_res)\n",
        "print(sim_res.mean())\n",
        "print(np.sqrt(sim_res.var()/n_samples))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          rho      lam0      lam1      lam2      lam3\n",
            "0    0.310419  1.150183  1.198657  1.257408  1.099657\n",
            "1    0.319387  1.125765  1.198075  1.263977  1.109190\n",
            "2    0.311540  1.152199  1.197347  1.242903  1.152226\n",
            "3    0.335476  1.133785  1.194594  1.255491  1.105391\n",
            "4    0.311475  1.156464  1.205699  1.251980  1.117362\n",
            "..        ...       ...       ...       ...       ...\n",
            "995  0.323583  1.127913  1.186675  1.241113  1.124534\n",
            "996  0.325488  1.133397  1.211668  1.252847  1.118864\n",
            "997  0.314595  1.168250  1.203992  1.246749  1.155023\n",
            "998  0.317887  1.135206  1.183842  1.249520  1.132108\n",
            "999  0.317812  1.144345  1.201510  1.243219  1.127537\n",
            "\n",
            "[1000 rows x 5 columns]\n",
            "rho     0.314524\n",
            "lam0    1.140279\n",
            "lam1    1.202684\n",
            "lam2    1.253499\n",
            "lam3    1.119633\n",
            "dtype: float64\n",
            "rho     0.000224\n",
            "lam0    0.000460\n",
            "lam1    0.000401\n",
            "lam2    0.000397\n",
            "lam3    0.000472\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "2V8SL-yh4Mwa",
        "outputId": "012feca8-18da-4190-a3ce-eb32121005a2"
      },
      "source": [
        "sns.histplot(data = sim_res, x = 'rho')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<AxesSubplot:xlabel='rho', ylabel='Count'>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s94_O4ke_9Ph",
        "outputId": "5566f5ea-7346-4591-8169-7f75c54ed1cc"
      },
      "source": [
        "# New with less samples!\n",
        "n_samples = 1000\n",
        "n = 614\n",
        "d = [11, 30, 37, 63, 27] # [11, 20212, 136545, 6042, 1252]\n",
        "k = [11, 30, 37, 63, 27]\n",
        "sim_res = simulate_micca(n=685, d=d, p=15, k=k, n_samples=n_samples)\n",
        "print(sim_res)\n",
        "print(sim_res.mean())\n",
        "print(np.sqrt(sim_res.var()/n_samples))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          rho          lam0      lam1      lam2      lam3      lam4\n",
            "0    0.243267  1.977240e-15  1.126108  1.168824  1.248423  1.114061\n",
            "1    0.245725  1.274841e-15  1.120201  1.153263  1.245933  1.101264\n",
            "2    0.247398  1.512380e-15  1.135160  1.152660  1.223348  1.119719\n",
            "3    0.240577  1.095152e-15  1.142939  1.171638  1.248281  1.092001\n",
            "4    0.246169  8.994811e-16  1.132303  1.165510  1.240342  1.105413\n",
            "..        ...           ...       ...       ...       ...       ...\n",
            "995  0.236015  9.861054e-16  1.095094  1.139718  1.226217  1.095792\n",
            "996  0.230564  6.184222e-15  1.121144  1.152957  1.252773  1.103905\n",
            "997  0.246119  1.519372e-15  1.155304  1.158981  1.248616  1.100601\n",
            "998  0.234147  1.049694e-15  1.114917  1.161805  1.233099  1.095462\n",
            "999  0.236737  1.504411e-15  1.128424  1.157019  1.244097  1.123560\n",
            "\n",
            "[1000 rows x 6 columns]\n",
            "rho     2.381290e-01\n",
            "lam0    1.612051e-15\n",
            "lam1    1.124981e+00\n",
            "lam2    1.157958e+00\n",
            "lam3    1.244977e+00\n",
            "lam4    1.108539e+00\n",
            "dtype: float64\n",
            "rho     1.825724e-04\n",
            "lam0    2.420113e-17\n",
            "lam1    4.734065e-04\n",
            "lam2    4.453338e-04\n",
            "lam3    4.027818e-04\n",
            "lam4    4.682485e-04\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kN4T11dQ71vL",
        "outputId": "9e56380f-03f8-4e1d-bda2-232e32c452ff"
      },
      "source": [
        "# New with less samples!\n",
        "# Exam 1\n",
        "n_samples = 1000\n",
        "n = 614\n",
        "d = [30, 37, 63, 27] # [11, 20212, 136545, 6042, 1252]\n",
        "k = [30, 37, 63, 27]\n",
        "sim_res = simulate_micca(n=n, d=d, p=15, k=k, n_samples=n_samples)\n",
        "print(sim_res)\n",
        "print(sim_res.mean())\n",
        "print(np.sqrt(sim_res.var()/n_samples))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          rho      lam0      lam1      lam2      lam3\n",
            "0    0.320578  1.130657  1.177922  1.240827  1.100804\n",
            "1    0.317757  1.131723  1.180814  1.259849  1.114117\n",
            "2    0.314573  1.133803  1.144913  1.270716  1.129283\n",
            "3    0.307691  1.109894  1.179461  1.241772  1.106463\n",
            "4    0.299075  1.142428  1.163395  1.265644  1.090644\n",
            "..        ...       ...       ...       ...       ...\n",
            "995  0.312658  1.132536  1.159907  1.239110  1.120385\n",
            "996  0.321436  1.127724  1.186606  1.244745  1.133853\n",
            "997  0.311329  1.131078  1.175646  1.254509  1.105949\n",
            "998  0.313112  1.136964  1.143419  1.245005  1.108425\n",
            "999  0.304826  1.134786  1.181821  1.243726  1.142509\n",
            "\n",
            "[1000 rows x 5 columns]\n",
            "rho     0.311571\n",
            "lam0    1.131281\n",
            "lam1    1.165546\n",
            "lam2    1.259031\n",
            "lam3    1.114528\n",
            "dtype: float64\n",
            "rho     0.000238\n",
            "lam0    0.000481\n",
            "lam1    0.000461\n",
            "lam2    0.000439\n",
            "lam3    0.000501\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbMI5sjhkU9-",
        "outputId": "13f323da-7ae0-44be-b5b4-e4b5adae4f1f"
      },
      "source": [
        "# New with less samples!\n",
        "# Exam 5\n",
        "n_samples = 1000\n",
        "n = 652\n",
        "d = [33, 35, 65, 24] # [11, 20212, 136545, 6042, 1252]\n",
        "k = [33, 35, 65, 24]\n",
        "sim_res = simulate_micca(n=n, d=d, p=15, k=k, n_samples=n_samples)\n",
        "print(sim_res)\n",
        "print(sim_res.mean())\n",
        "print(np.sqrt(sim_res.var()/n_samples))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          rho      lam0      lam1      lam2      lam3\n",
            "0    0.298904  1.137406  1.117267  1.274493  1.105144\n",
            "1    0.297770  1.155581  1.144521  1.234707  1.103742\n",
            "2    0.296310  1.132263  1.160156  1.246977  1.083557\n",
            "3    0.295986  1.150054  1.148310  1.268373  1.102212\n",
            "4    0.291613  1.126885  1.176688  1.250780  1.102819\n",
            "..        ...       ...       ...       ...       ...\n",
            "995  0.293826  1.149765  1.138378  1.265901  1.104733\n",
            "996  0.295106  1.147655  1.143307  1.242170  1.125958\n",
            "997  0.289640  1.176098  1.173583  1.270809  1.087282\n",
            "998  0.294295  1.139120  1.141223  1.242228  1.080656\n",
            "999  0.298060  1.151335  1.149921  1.243482  1.092042\n",
            "\n",
            "[1000 rows x 5 columns]\n",
            "rho     0.300501\n",
            "lam0    1.142927\n",
            "lam1    1.152455\n",
            "lam2    1.257498\n",
            "lam3    1.092104\n",
            "dtype: float64\n",
            "rho     0.000238\n",
            "lam0    0.000456\n",
            "lam1    0.000456\n",
            "lam2    0.000407\n",
            "lam3    0.000508\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mccbybhlkVFZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlpA2a9XkVO4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpw52UylSVBL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43dBxPCtSU2T"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yTzMkHHNhoQ",
        "outputId": "8b587eb0-97d9-44b9-8410-73766fe69d78"
      },
      "source": [
        "d=[11, 33, 49, 66, 29]\n",
        "n=685\n",
        "datasets = [torch.tensor(np.random.normal(loc=0, scale=1, size=n*di).reshape((n,di))) for di in d]\n",
        "micca.pca(datasets[0]).lam"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.1180, 1.0767, 1.0380, 1.0327, 1.0169, 1.0079, 0.9731, 0.9564, 0.9440, 0.9255, 0.8876], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbtsQqBQQpK9",
        "outputId": "4b19e97e-a0ee-40c1-9851-982ce1151b72"
      },
      "source": [
        "n = 685\n",
        "d = 10000\n",
        "X = torch.tensor(np.random.normal(loc=0, scale=1, size=n*d).reshape((n, d)))\n",
        "Ux, Sx, VxT = torch.linalg.svd(X)\n",
        "Y = (X @ X.T)/n\n",
        "Uy, Sy, _ = torch.linalg.svd(Y)\n",
        "print(1 + np.sqrt(d / n))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.82080359950435\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tnono8_4TFtK",
        "outputId": "5b1fcbf0-e8c5-4f89-828e-da4fd1a305f0"
      },
      "source": [
        "Sx**2/n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([23.1014, 22.9944, 22.9480, 22.8604, 22.7819, 22.6875, 22.5659, 22.4613, 22.4232, 22.3789, 22.3145, 22.2555, 22.2165, 22.1716, 22.1452, 22.0848, 21.9862, 21.9448, 21.9153, 21.8772, 21.8629,\n",
              "        21.8335, 21.7476, 21.7210, 21.6920, 21.6258, 21.5932, 21.5451, 21.5103, 21.4658, 21.4472, 21.4007, 21.3470, 21.3414, 21.2995, 21.2793, 21.2356, 21.1819, 21.1731, 21.1271, 21.0862, 21.0436,\n",
              "        21.0244, 21.0203, 20.9288, 20.9166, 20.8930, 20.8795, 20.8080, 20.7961, 20.7636, 20.6837, 20.6616, 20.6151, 20.5769, 20.5731, 20.5140, 20.4938, 20.4605, 20.4276, 20.4025, 20.3729, 20.3349,\n",
              "        20.3232, 20.2903, 20.2458, 20.2079, 20.1697, 20.1643, 20.1269, 20.0989, 20.0729, 20.0327, 20.0298, 19.9921, 19.9657, 19.9461, 19.8844, 19.8769, 19.8670, 19.8478, 19.7994, 19.7700, 19.7489,\n",
              "        19.7204, 19.6967, 19.6754, 19.6086, 19.5939, 19.5796, 19.5332, 19.5253, 19.4732, 19.4507, 19.4420, 19.3882, 19.3799, 19.3575, 19.3064, 19.2603, 19.2565, 19.2323, 19.2260, 19.1518, 19.1501,\n",
              "        19.1046, 19.0843, 19.0495, 19.0359, 19.0090, 18.9888, 18.9728, 18.9559, 18.9431, 18.8785, 18.8643, 18.8507, 18.8122, 18.8053, 18.7840, 18.7767, 18.7396, 18.7076, 18.6679, 18.6551, 18.6369,\n",
              "        18.5901, 18.5778, 18.5355, 18.5165, 18.4897, 18.4635, 18.4587, 18.4540, 18.4288, 18.3946, 18.3764, 18.3617, 18.3112, 18.3065, 18.2746, 18.2541, 18.2322, 18.1945, 18.1687, 18.1351, 18.1279,\n",
              "        18.1127, 18.0965, 18.0647, 18.0454, 18.0368, 18.0083, 17.9646, 17.9519, 17.9061, 17.8966, 17.8878, 17.8708, 17.8281, 17.8240, 17.8008, 17.7836, 17.7565, 17.7160, 17.6973, 17.6855, 17.6709,\n",
              "        17.6125, 17.6091, 17.5892, 17.5660, 17.5364, 17.5082, 17.4799, 17.4568, 17.4267, 17.4207, 17.4024, 17.3825, 17.3802, 17.3468, 17.3448, 17.3068, 17.2931, 17.2722, 17.2487, 17.2139, 17.2035,\n",
              "        17.1802, 17.1636, 17.1251, 17.1072, 17.0828, 17.0737, 17.0552, 17.0517, 17.0233, 16.9951, 16.9702, 16.9612, 16.9320, 16.9047, 16.8907, 16.8508, 16.8441, 16.8392, 16.8194, 16.8019, 16.7898,\n",
              "        16.7616, 16.7401, 16.7201, 16.6809, 16.6415, 16.6286, 16.6209, 16.5920, 16.5837, 16.5652, 16.5505, 16.5302, 16.5091, 16.4725, 16.4537, 16.4464, 16.4152, 16.4049, 16.3848, 16.3634, 16.3297,\n",
              "        16.3084, 16.2824, 16.2741, 16.2580, 16.2426, 16.2201, 16.2127, 16.1704, 16.1644, 16.1515, 16.1390, 16.1114, 16.0762, 16.0656, 16.0511, 16.0486, 16.0187, 15.9812, 15.9750, 15.9672, 15.9598,\n",
              "        15.9314, 15.9142, 15.8785, 15.8635, 15.8394, 15.8055, 15.7960, 15.7669, 15.7432, 15.7417, 15.7258, 15.7133, 15.6910, 15.6598, 15.6400, 15.6277, 15.6024, 15.5919, 15.5686, 15.5562, 15.5297,\n",
              "        15.5159, 15.4990, 15.4814, 15.4657, 15.4576, 15.4181, 15.3975, 15.3821, 15.3755, 15.3520, 15.3292, 15.3154, 15.2984, 15.2772, 15.2569, 15.2440, 15.2280, 15.2015, 15.1933, 15.1782, 15.1592,\n",
              "        15.1514, 15.1297, 15.1230, 15.0953, 15.0752, 15.0593, 15.0339, 15.0240, 14.9983, 14.9827, 14.9640, 14.9589, 14.9315, 14.9267, 14.8817, 14.8650, 14.8434, 14.8290, 14.8163, 14.7784, 14.7694,\n",
              "        14.7505, 14.7314, 14.7147, 14.6928, 14.6712, 14.6652, 14.6583, 14.6469, 14.6246, 14.6060, 14.5933, 14.5871, 14.5660, 14.5382, 14.5048, 14.4843, 14.4741, 14.4662, 14.4457, 14.4315, 14.4102,\n",
              "        14.4041, 14.3718, 14.3697, 14.3620, 14.3315, 14.2937, 14.2880, 14.2728, 14.2618, 14.2433, 14.2390, 14.2324, 14.2078, 14.2017, 14.1612, 14.1357, 14.1262, 14.1008, 14.0897, 14.0637, 14.0561,\n",
              "        14.0395, 14.0302, 14.0135, 13.9859, 13.9715, 13.9417, 13.9288, 13.8992, 13.8951, 13.8827, 13.8487, 13.8347, 13.8171, 13.8110, 13.7937, 13.7766, 13.7362, 13.7205, 13.7165, 13.6955, 13.6592,\n",
              "        13.6380, 13.6234, 13.6190, 13.5859, 13.5727, 13.5510, 13.5478, 13.5236, 13.5174, 13.4935, 13.4779, 13.4659, 13.4376, 13.4262, 13.4160, 13.3960, 13.3784, 13.3703, 13.3584, 13.3341, 13.3147,\n",
              "        13.2945, 13.2667, 13.2627, 13.2536, 13.2280, 13.2193, 13.1975, 13.1927, 13.1648, 13.1435, 13.1223, 13.1158, 13.1076, 13.0824, 13.0695, 13.0557, 13.0367, 13.0170, 13.0011, 12.9970, 12.9766,\n",
              "        12.9364, 12.9225, 12.9045, 12.8959, 12.8875, 12.8575, 12.8474, 12.8284, 12.8155, 12.7951, 12.7793, 12.7691, 12.7514, 12.7318, 12.7138, 12.7129, 12.6989, 12.6588, 12.6527, 12.6182, 12.6000,\n",
              "        12.5753, 12.5719, 12.5503, 12.5286, 12.5199, 12.5093, 12.4776, 12.4687, 12.4572, 12.4379, 12.4291, 12.4161, 12.3801, 12.3726, 12.3499, 12.3376, 12.3234, 12.3089, 12.2989, 12.2802, 12.2778,\n",
              "        12.2475, 12.2333, 12.2182, 12.2116, 12.1914, 12.1751, 12.1590, 12.1538, 12.1229, 12.1190, 12.0897, 12.0850, 12.0736, 12.0496, 12.0215, 12.0123, 12.0044, 11.9805, 11.9757, 11.9579, 11.9461,\n",
              "        11.9250, 11.8992, 11.8864, 11.8730, 11.8677, 11.8470, 11.8315, 11.8124, 11.7944, 11.7827, 11.7649, 11.7518, 11.7276, 11.7186, 11.6944, 11.6703, 11.6590, 11.6482, 11.6392, 11.6302, 11.5927,\n",
              "        11.5805, 11.5715, 11.5616, 11.5343, 11.5259, 11.5110, 11.4966, 11.4677, 11.4569, 11.4387, 11.4073, 11.4053, 11.3648, 11.3615, 11.3465, 11.3111, 11.3054, 11.2984, 11.2693, 11.2582, 11.2422,\n",
              "        11.2327, 11.2214, 11.2102, 11.1961, 11.1697, 11.1624, 11.1349, 11.1199, 11.1068, 11.0969, 11.0668, 11.0538, 11.0487, 11.0386, 11.0100, 10.9958, 10.9606, 10.9346, 10.9241, 10.9170, 10.9013,\n",
              "        10.8951, 10.8695, 10.8522, 10.8325, 10.8158, 10.7986, 10.7664, 10.7603, 10.7433, 10.7174, 10.7162, 10.6920, 10.6679, 10.6511, 10.6491, 10.6143, 10.5883, 10.5756, 10.5639, 10.5499, 10.5400,\n",
              "        10.5310, 10.5133, 10.4770, 10.4708, 10.4640, 10.4539, 10.4445, 10.4078, 10.3910, 10.3868, 10.3680, 10.3497, 10.3287, 10.3189, 10.3040, 10.2680, 10.2507, 10.2429, 10.2145, 10.2074, 10.1942,\n",
              "        10.1550, 10.1430, 10.1111, 10.0991, 10.0866, 10.0666, 10.0539, 10.0419, 10.0305, 10.0008,  9.9903,  9.9733,  9.9470,  9.9275,  9.9132,  9.9041,  9.8863,  9.8657,  9.8517,  9.8413,  9.8102,\n",
              "         9.7933,  9.7810,  9.7751,  9.7415,  9.7254,  9.7039,  9.6845,  9.6781,  9.6536,  9.6331,  9.6137,  9.5997,  9.5642,  9.5456,  9.5176,  9.5093,  9.5036,  9.4977,  9.4664,  9.4525,  9.4411,\n",
              "         9.4355,  9.4025,  9.3765,  9.3643,  9.3428,  9.3329,  9.3123,  9.2836,  9.2745,  9.2468,  9.2255,  9.1917,  9.1798,  9.1584,  9.1433,  9.1161,  9.0951,  9.0751,  9.0704,  9.0396,  9.0339,\n",
              "         9.0104,  9.0034,  8.9704,  8.9446,  8.9069,  8.8986,  8.8637,  8.8501,  8.8348,  8.7760,  8.7659,  8.7358,  8.7327,  8.6961,  8.6775,  8.6542,  8.5999,  8.5897,  8.5568,  8.5329,  8.4990,\n",
              "         8.4672,  8.4305,  8.3883,  8.3521,  8.3018,  8.2778,  8.2581,  8.2160,  8.1853,  8.1144,  8.0851,  7.9998,  7.9217], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJqrnzzpQ7SW",
        "outputId": "4c263169-9c72-45e6-b2d0-d03ce57dadae"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.9998, 0.9903, 1.0008, 1.0003, 1.0009, 1.0005, 1.0010, 1.0007, 1.0014, 0.9956, 1.0010, 0.9982, 1.0015, 0.9964, 0.9987, 1.0014, 0.9978, 1.0014, 1.0012, 1.0014, 1.0012, 1.0014, 1.0000, 1.0014,\n",
              "        1.0014, 1.0014, 1.0015, 0.9987, 0.9989, 1.0012, 0.9976, 1.0014, 0.9985, 0.9947, 1.0010, 0.9990, 0.9971, 0.9979, 0.9993, 1.0002, 1.0012, 1.0012, 1.0014, 1.0003, 1.0015, 1.0013, 1.0011, 1.0012,\n",
              "        0.9968, 1.0014, 0.9969, 0.9997, 1.0014, 0.9999, 1.0002, 0.9945, 1.0010, 1.0002, 1.0007, 1.0006, 1.0006, 1.0007, 0.9966, 0.9991, 0.9993, 1.0014, 1.0009, 0.9998, 0.9994, 0.9979, 1.0014, 0.9993,\n",
              "        0.9930, 1.0013, 1.0014, 1.0013, 1.0014, 0.9975, 1.0003, 0.9996, 1.0013, 1.0011, 1.0010, 0.9994, 1.0014, 1.0010, 1.0006, 0.9985, 0.9990, 1.0014, 1.0000, 0.9978, 0.9998, 1.0001, 1.0014, 1.0012,\n",
              "        0.9998, 1.0009, 1.0009, 1.0013, 1.0013, 0.9990, 1.0014, 1.0010, 1.0003, 1.0015, 0.9998, 1.0014, 1.0010, 1.0004, 1.0011, 1.0011, 1.0009, 0.9981, 1.0013, 1.0004, 0.9978, 1.0006, 1.0015, 1.0010,\n",
              "        1.0015, 1.0014, 0.9991, 0.9962, 1.0011, 0.9990, 1.0011, 0.9949, 1.0013, 1.0009, 0.9992, 1.0003, 1.0012, 0.9997, 0.9980, 1.0005, 0.9955, 1.0013, 1.0015, 0.9979, 1.0009, 1.0012, 1.0014, 0.9890,\n",
              "        0.9993, 1.0012, 1.0015, 1.0012, 1.0012, 0.9887, 1.0014, 0.9915, 1.0012, 0.9971, 1.0008, 1.0001, 0.9993, 0.9956, 1.0002, 1.0012, 0.9990, 1.0013, 1.0007, 0.9942, 1.0012, 1.0004, 1.0010, 1.0009,\n",
              "        1.0013, 1.0012, 1.0015, 1.0012, 1.0004, 0.9968, 1.0001, 0.9995, 0.9995, 1.0009, 0.9978, 1.0014, 1.0014, 1.0009, 0.9961, 0.9957, 0.9969, 1.0015, 0.9871, 1.0013, 1.0015, 0.9997, 1.0010, 1.0005,\n",
              "        1.0001, 1.0005, 1.0012, 0.9996, 1.0011, 0.9994, 1.0012, 0.9996, 1.0014, 0.9998, 1.0004, 0.9997, 1.0000, 1.0004, 1.0015, 0.9987, 1.0015, 1.0007, 1.0007, 1.0003, 1.0002, 0.9997, 1.0011, 1.0009,\n",
              "        1.0008, 1.0008, 1.0015, 1.0010, 1.0008, 1.0005, 0.9994, 1.0012, 1.0015, 1.0011, 0.9967, 0.9992, 0.9999, 1.0003, 1.0008, 1.0007, 1.0001, 1.0011, 1.0015, 0.9995, 0.9998, 1.0006, 1.0002, 1.0013,\n",
              "        1.0008, 1.0014, 1.0010, 1.0003, 1.0014, 0.9999, 0.9991, 0.9957, 0.9993, 1.0014, 0.9995, 1.0015, 0.9989, 1.0013, 1.0011, 1.0013, 1.0014, 0.9982, 0.9974, 1.0001, 1.0014, 0.9993, 0.9966, 1.0001,\n",
              "        1.0014, 1.0003, 1.0013, 1.0000, 1.0002, 1.0015, 1.0002, 1.0008, 0.9990, 1.0003, 1.0014, 1.0000, 1.0003, 1.0006, 0.9963, 0.9998, 1.0004, 1.0012, 0.9986, 1.0004, 0.9994, 1.0006, 0.9981, 1.0014,\n",
              "        0.9991, 1.0014, 0.9917, 1.0013, 1.0001, 1.0014, 1.0008, 1.0012, 1.0013, 1.0014, 1.0009, 1.0011, 1.0014, 1.0012, 1.0002, 0.9978, 1.0004, 0.9979, 1.0009, 1.0006, 1.0006, 1.0009, 1.0009, 1.0015,\n",
              "        1.0011, 0.9971, 1.0014, 1.0013, 1.0013, 1.0013, 1.0003, 1.0014, 1.0014, 1.0014, 1.0009, 1.0014, 0.9990, 1.0010, 1.0012, 1.0003, 0.9980, 1.0006, 1.0010, 1.0013, 0.9925, 1.0014, 1.0007, 1.0014,\n",
              "        0.9982, 1.0013, 1.0012, 1.0009, 1.0012, 1.0014, 1.0009, 1.0007, 1.0005, 1.0010, 1.0014, 0.9972, 1.0012, 1.0015, 1.0014, 1.0005, 1.0012, 1.0013, 1.0012, 1.0014, 0.9945, 0.9998, 0.9987, 1.0012,\n",
              "        1.0010, 0.9938, 0.9998, 0.9999, 1.0014, 1.0007, 1.0007, 1.0008, 0.9971, 0.9908, 0.9979, 0.9997, 0.9998, 0.9984, 1.0013, 1.0015, 1.0006, 1.0011, 1.0008, 1.0003, 1.0006, 1.0013, 1.0006, 1.0004,\n",
              "        1.0012, 0.9999, 0.9996, 1.0015, 0.9986, 1.0000, 1.0006, 1.0006, 1.0010, 1.0014, 1.0013, 1.0007, 1.0011, 1.0015, 1.0007, 1.0005, 1.0014, 0.9967, 0.9978, 1.0007, 1.0015, 0.9976, 0.9982, 1.0014,\n",
              "        1.0013, 1.0012, 0.9963, 1.0012, 0.9915, 1.0005, 1.0010, 1.0001, 1.0009, 1.0010, 1.0006, 1.0006, 1.0007, 1.0009, 1.0014, 1.0012, 1.0012, 1.0005, 0.9998, 1.0013, 1.0014, 1.0015, 1.0006, 1.0015,\n",
              "        1.0013, 0.9972, 1.0004, 1.0014, 1.0015, 0.9971, 1.0002, 1.0014, 1.0007, 1.0005, 1.0012, 1.0012, 0.9988, 1.0013, 1.0015, 0.9979, 1.0009, 1.0014, 0.9984, 1.0013, 1.0003, 1.0014, 1.0012, 1.0008,\n",
              "        0.9992, 0.9967, 1.0012, 0.9970, 1.0005, 0.9999, 1.0001, 0.9969, 1.0014, 0.9965, 1.0012, 0.9969, 1.0011, 1.0015, 0.9981, 0.9998, 1.0012, 1.0015, 1.0007, 1.0015, 1.0014, 1.0015, 1.0014, 0.9964,\n",
              "        0.9953, 1.0012, 0.9994, 1.0013, 1.0014, 0.9933, 1.0012, 1.0014, 1.0015, 0.9981, 1.0013, 0.9993, 1.0014, 0.9997, 1.0007, 0.9983, 1.0014, 1.0014, 0.9985, 1.0008, 1.0014, 1.0001, 1.0015, 0.9942,\n",
              "        1.0003, 0.9987, 1.0015, 1.0015, 1.0011, 1.0014, 0.9999, 1.0000, 1.0014, 1.0012, 0.9998, 1.0015, 1.0011, 0.9960, 1.0007, 1.0006, 1.0014, 0.9950, 0.9976, 0.9984, 1.0010, 0.9964, 1.0015, 1.0009,\n",
              "        0.9999, 1.0012, 1.0003, 0.9956, 0.9948, 1.0013, 1.0015, 0.9977, 0.9988, 0.9986, 1.0002, 1.0012, 1.0009, 1.0014, 0.9961, 1.0013, 1.0011, 1.0007, 0.9986, 0.9994, 0.9930, 1.0008, 1.0014, 1.0011,\n",
              "        0.9963, 1.0007, 1.0003, 1.0002, 0.9993, 0.9953, 0.9994, 0.9996, 1.0000, 1.0013, 1.0013, 1.0000, 1.0014, 1.0003, 1.0009, 1.0014, 0.9999, 1.0014, 1.0014, 1.0012, 0.9994, 1.0012, 0.9918, 1.0003,\n",
              "        1.0014, 1.0014, 0.9988, 1.0014, 1.0014, 1.0014, 1.0014, 1.0015, 1.0015, 0.9976, 1.0013, 0.9934, 1.0008, 1.0000, 1.0000, 1.0002, 1.0014, 0.9972, 1.0005, 1.0014, 0.9977, 0.9984, 1.0014, 1.0012,\n",
              "        0.9964, 0.9972, 1.0014, 0.9997, 1.0014, 1.0012, 0.9985, 1.0014, 1.0015, 1.0013, 1.0006, 1.0013, 1.0014, 1.0011, 0.9942, 1.0007, 0.9992, 1.0015, 1.0000, 1.0002, 1.0014, 1.0000, 1.0001, 0.9990,\n",
              "        1.0012, 1.0015, 0.9990, 1.0015, 1.0014, 1.0013, 0.9969, 1.0012, 1.0011, 1.0014, 0.9991, 1.0003, 1.0014, 1.0002, 0.9989, 1.0014, 1.0013, 1.0014, 1.0014, 1.0015, 0.9969, 1.0012, 1.0010, 1.0010,\n",
              "        1.0008, 1.0006, 1.0012, 1.0015, 1.0015, 1.0010, 1.0003, 0.9994, 1.0005, 1.0013, 0.9994, 1.0012, 1.0012, 1.0008, 0.9987, 1.0004, 1.0008, 1.0004, 0.9996, 1.0006, 1.0012, 0.9940, 1.0015, 1.0014,\n",
              "        1.0005, 1.0006, 1.0013, 0.9976, 1.0005, 1.0000, 1.0008, 1.0013, 1.0004, 1.0013, 1.0004, 0.9982, 0.9974], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmhzK4JSxZmP",
        "outputId": "46cf41c3-34cc-4525-d67f-0e36b4dd1443"
      },
      "source": [
        "(A.T @ A).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 313
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vHnd-JUxCa-",
        "outputId": "4387a188-023e-4dc5-f25e-b02e6f314f18"
      },
      "source": [
        "A = V_splits[0]\n",
        "print( A @ torch.linalg.lstsq(A.T @ A, A.T)[0] )\n",
        "print( A @ torch.linalg.inv(A.T @ A) @ A.T)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.5646,  0.2357, -0.2792, -0.0367,  0.0826, -0.0040,  0.0131,  0.2886,  0.0513,  0.1345],\n",
            "        [ 0.2357,  0.1619, -0.1894, -0.1263, -0.0884,  0.0072,  0.0829, -0.0060, -0.0126,  0.1157],\n",
            "        [-0.2792, -0.1894,  0.4480,  0.0654,  0.2382, -0.1482,  0.0965,  0.0093,  0.1466,  0.1399],\n",
            "        [-0.0367, -0.1263,  0.0654,  0.2247,  0.1604,  0.0342, -0.2040,  0.1998,  0.0089, -0.2100],\n",
            "        [ 0.0826, -0.0884,  0.2382,  0.1604,  0.3339, -0.1032, -0.0307,  0.2910,  0.1543,  0.0722],\n",
            "        [-0.0040,  0.0072, -0.1482,  0.0342, -0.1032,  0.0878, -0.1079, -0.0240, -0.0874, -0.1625],\n",
            "        [ 0.0131,  0.0829,  0.0965, -0.2040, -0.0307, -0.1079,  0.2573, -0.1416,  0.0726,  0.3086],\n",
            "        [ 0.2886, -0.0060,  0.0093,  0.1998,  0.2910, -0.0240, -0.1416,  0.3995,  0.0979, -0.0414],\n",
            "        [ 0.0513, -0.0126,  0.1466,  0.0089,  0.1543, -0.0874,  0.0726,  0.0979,  0.1010,  0.1419],\n",
            "        [ 0.1345,  0.1157,  0.1399, -0.2100,  0.0722, -0.1625,  0.3086, -0.0414,  0.1419,  0.4213]], dtype=torch.float64)\n",
            "tensor([[ 0.5646,  0.2357, -0.2792, -0.0367,  0.0826, -0.0040,  0.0131,  0.2886,  0.0513,  0.1345],\n",
            "        [ 0.2357,  0.1619, -0.1894, -0.1263, -0.0884,  0.0072,  0.0829, -0.0060, -0.0126,  0.1157],\n",
            "        [-0.2792, -0.1894,  0.4480,  0.0654,  0.2382, -0.1482,  0.0965,  0.0093,  0.1466,  0.1399],\n",
            "        [-0.0367, -0.1263,  0.0654,  0.2247,  0.1604,  0.0342, -0.2040,  0.1998,  0.0089, -0.2100],\n",
            "        [ 0.0826, -0.0884,  0.2382,  0.1604,  0.3339, -0.1032, -0.0307,  0.2910,  0.1543,  0.0722],\n",
            "        [-0.0040,  0.0072, -0.1482,  0.0342, -0.1032,  0.0878, -0.1079, -0.0240, -0.0874, -0.1625],\n",
            "        [ 0.0131,  0.0829,  0.0965, -0.2040, -0.0307, -0.1079,  0.2573, -0.1416,  0.0726,  0.3086],\n",
            "        [ 0.2886, -0.0060,  0.0093,  0.1998,  0.2910, -0.0240, -0.1416,  0.3995,  0.0979, -0.0414],\n",
            "        [ 0.0513, -0.0126,  0.1466,  0.0089,  0.1543, -0.0874,  0.0726,  0.0979,  0.1010,  0.1419],\n",
            "        [ 0.1345,  0.1157,  0.1399, -0.2100,  0.0722, -0.1625,  0.3086, -0.0414,  0.1419,  0.4213]], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZTB-EnARjdv"
      },
      "source": [
        "# testing private\n",
        "\n",
        "def make_P_mats(A_list):\n",
        "  P_pars = [A @ torch.linalg.lstsq(A.T @ A, A.T)[0] for A in A_list]\n",
        "  P_perps = [torch.eye(P.shape[0]) - P for P in P_pars]\n",
        "  return P_pars, P_perps\n",
        "\n",
        "n = 1000\n",
        "d = [10, 20, 30]\n",
        "dimensions = [10, 20, 30]\n",
        "c_shared = 3\n",
        "n_sets = len(d)\n",
        "datasets = [torch.tensor(np.random.normal(loc=0, scale=1, size=n*di).reshape((n, di))) for di in d]\n",
        "data_pcs = [micca.pca(ds) for ds in datasets]\n",
        "U_splits = [data_pc.U[:, 0:k] for data_pc, k in zip(data_pcs, dimensions)]\n",
        "U_all = torch.cat(U_splits, dim=1)\n",
        "M = U_all.T @ U_all\n",
        "values, vectors = torch.linalg.eigh(M)\n",
        "values = torch.flip(values, dims=[0])\n",
        "vectors = torch.flip(vectors, dims=[1])\n",
        "rho = (values[0:c_shared] - 1)/(n_sets - 1)\n",
        "V = np.sqrt(n_sets) * vectors[:, 0:c_shared]\n",
        "dimsum = np.concatenate([[0], np.cumsum(dimensions, 0)])\n",
        "V_splits = [V[i:j, :] for i, j in zip(dimsum[:-1], dimsum[1:])]\n",
        "P_pars, P_perps = make_P_mats(V_splits)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRK6iaTXynCK",
        "outputId": "6f43b559-1881-47e1-e876-6105d9a8683f"
      },
      "source": [
        "X0 = datasets[0]\n",
        "P0_par = P_pars[0]\n",
        "P0_perp = P_perps[0]\n",
        "U0, l0, V0T = torch.linalg.svd(X0, full_matrices=False)\n",
        "X0_par = U0 @ P0_par * l0 @ V0T\n",
        "X0_perp = U0 @ P0_perp * l0 @ V0T\n",
        "\n",
        "print(torch.linalg.svd(X0_perp).S[0:3])\n",
        "print(torch.linalg.svd(X0_perp).U[:, 0:3])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([33.9038, 33.1173, 32.1625], dtype=torch.float64)\n",
            "tensor([[-0.0288, -0.0631,  0.0124],\n",
            "        [ 0.0073, -0.0105,  0.0092],\n",
            "        [ 0.0254,  0.0054, -0.0451],\n",
            "        ...,\n",
            "        [ 0.0029,  0.0145, -0.0292],\n",
            "        [ 0.0131,  0.0160, -0.0085],\n",
            "        [ 0.0385,  0.0132,  0.0306]], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PJvSz_Tym45",
        "outputId": "c048dd5c-379e-4b1e-88d4-c45680b535d8"
      },
      "source": [
        "U0_perp = torch.linalg.svd(P0_perp).U\n",
        "idk = U0 @ P0_perp * l0\n",
        "l0perp = torch.linalg.svd(idk).S\n",
        "print(torch.linalg.svd(idk).S[0:3])  # EVs of resid mat. EVs of resid cov are this**2/n\n",
        "print(torch.linalg.svd(idk).U[:, 0:3])  # Left SVs of resid mat"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([33.9038, 33.1173, 32.1625], dtype=torch.float64)\n",
            "tensor([[-0.0288, -0.0631, -0.0124],\n",
            "        [ 0.0073, -0.0105, -0.0092],\n",
            "        [ 0.0254,  0.0054,  0.0451],\n",
            "        ...,\n",
            "        [ 0.0029,  0.0145,  0.0292],\n",
            "        [ 0.0131,  0.0160,  0.0085],\n",
            "        [ 0.0385,  0.0132, -0.0306]], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1P6W41zRsEV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RepY0RGRsOo",
        "outputId": "377ff66f-022c-4520-9ada-924b9c458431"
      },
      "source": [
        "n = 1000\n",
        "d = 100\n",
        "sigma = np.sqrt(np.random.normal(1, 1, size = d)**2)\n",
        "print(min(sigma**2), max(sigma**2), np.mean(sigma**2), np.median(sigma**2))\n",
        "\n",
        "Y = np.random.normal(scale = sigma, size = (n,d))\n",
        "Y = Y - np.mean(Y, 0)\n",
        "\n",
        "C = Y.T @ Y / n\n",
        "\n",
        "np.linalg.svd(C)[1][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8.105698520320091e-05 13.55598235909839 1.9348721759263083 1.2117210419185407\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14.181129383287796"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOZfDWmZSzY4",
        "outputId": "a21dbe47-55a5-4712-8388-d8ff044d2ec6"
      },
      "source": [
        "np.max(sigma**2)*(1 + np.sqrt(d/n))**2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23.485136630170928"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLG-dF7ZUANI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dece5823-0c54-4f25-c56f-3837be0cce6f"
      },
      "source": [
        "np.linalg.svd(np.diag(sigma**2))[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.35559824e+01, 9.38379972e+00, 7.52784029e+00, 7.37787979e+00, 6.91764503e+00, 6.11886543e+00, 5.67558693e+00, 5.40229265e+00, 5.00933889e+00, 4.83701856e+00, 4.78366940e+00, 4.27342312e+00,\n",
              "       4.14347345e+00, 4.05536746e+00, 4.00851988e+00, 3.99264250e+00, 3.93960886e+00, 3.90045029e+00, 3.89416360e+00, 3.84939090e+00, 3.01619510e+00, 3.00857187e+00, 2.71967729e+00, 2.57733871e+00,\n",
              "       2.57598602e+00, 2.51706790e+00, 2.47780558e+00, 2.38936363e+00, 2.09716754e+00, 2.08983359e+00, 1.96895257e+00, 1.96836496e+00, 1.94523424e+00, 1.90472145e+00, 1.86342522e+00, 1.83026886e+00,\n",
              "       1.65594659e+00, 1.54901228e+00, 1.54812609e+00, 1.53865815e+00, 1.49557017e+00, 1.49437897e+00, 1.45611896e+00, 1.42534034e+00, 1.37257308e+00, 1.34763312e+00, 1.23864946e+00, 1.21938282e+00,\n",
              "       1.21897592e+00, 1.21572061e+00, 1.20772148e+00, 1.18979589e+00, 1.10386189e+00, 1.09743010e+00, 1.07302856e+00, 1.06506790e+00, 1.03161531e+00, 1.01993493e+00, 9.97146691e-01, 8.96470121e-01,\n",
              "       8.77766932e-01, 8.75451337e-01, 8.34948714e-01, 8.27671274e-01, 7.81451616e-01, 7.03086628e-01, 6.89063654e-01, 6.71628456e-01, 6.45512002e-01, 6.03040987e-01, 5.38963331e-01, 4.88746792e-01,\n",
              "       4.82420611e-01, 4.42681010e-01, 3.57148748e-01, 3.36750565e-01, 3.24175032e-01, 3.20943993e-01, 2.70727413e-01, 2.57387907e-01, 2.39318438e-01, 2.17052995e-01, 1.87548358e-01, 1.74082912e-01,\n",
              "       1.39408429e-01, 1.16536010e-01, 1.15512897e-01, 1.10291838e-01, 1.09177075e-01, 1.04866550e-01, 9.99223782e-02, 9.33955194e-02, 8.53906731e-02, 7.88122330e-02, 7.28704827e-02, 6.32030408e-02,\n",
              "       5.75566263e-02, 3.40672123e-02, 3.46278446e-03, 8.10569852e-05])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOMu25WriDoE",
        "outputId": "55453233-43e4-4579-abdb-c4629f71a089"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13.909968281510594"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3mLmVz3iNfr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}