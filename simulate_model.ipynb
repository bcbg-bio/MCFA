{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.distributions as tdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 3  # total number of datasets\n",
    "N = 1000  # total number of samples\n",
    "d = 5  # latent variable z dimension\n",
    "y_dims = torch.tensor([20, 30, 50])  # dimensions of each dataset\n",
    "x_dims = torch.tensor([4, 5, 6])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_W_L_Phi(y_dims, x_dims, d=5, M=3, minval=-100, maxval=100, max_noise=5):\n",
    "    all_Ws = []\n",
    "    all_Ls = []\n",
    "    all_Phis = []\n",
    "    \n",
    "    for i, y_val in enumerate(y_dims):\n",
    "        # declare new uniform distributions from which to sample ground truth W, L, and Phi for each dataset\n",
    "        W_uniform = tdist.uniform.Uniform(torch.ones(y_val, d)*minval, torch.ones(y_val, d)*maxval)\n",
    "        L_uniform = tdist.uniform.Uniform(torch.ones(y_val, x_dims[i])*minval, torch.ones(y_val, x_dims[i])*maxval)\n",
    "        Phi_uniform = tdist.uniform.Uniform(torch.zeros(y_val), max_noise*torch.ones(y_val))\n",
    "\n",
    "        # store ground truth W, L, and Phi\n",
    "        all_Ws.append(W_uniform.sample())\n",
    "        all_Ls.append(L_uniform.sample())\n",
    "        all_Phis.append(torch.diag(Phi_uniform.sample()))\n",
    "    \n",
    "    return all_Ws, all_Ls, all_Phis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_Ws, all_Ls, all_Phis = generate_W_L_Phi(y_dims, x_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([20, 5]), torch.Size([30, 5]), torch.Size([50, 5])]\n",
      "[torch.Size([20, 4]), torch.Size([30, 5]), torch.Size([50, 6])]\n",
      "[torch.Size([20, 20]), torch.Size([30, 30]), torch.Size([50, 50])]\n"
     ]
    }
   ],
   "source": [
    "print([W.shape for W in all_Ws])\n",
    "print([L.shape for L in all_Ls])\n",
    "print([Phi.shape for Phi in all_Phis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples(all_Ws, all_Ls, all_Phis, y_dims, x_dims, N=1000, d=5):\n",
    "    datasets = [torch.zeros(1, y_d) for y_d in y_dims]\n",
    "\n",
    "    # z-distribution remains fixed\n",
    "    z_distribution = tdist.multivariate_normal.MultivariateNormal(torch.zeros(d), torch.eye(d))\n",
    "    \n",
    "    # simulate the graphical model\n",
    "    for sample in range(N):\n",
    "        print('Generating sample: {}/{}'.format(sample, N), end='\\r', flush=True)\n",
    "        # for each sample, retrieve the latent z latent variable\n",
    "        z = z_distribution.sample()\n",
    "        # for each dataset, compute the dataset-specific mean and variance, and obtain 1 sample\n",
    "        for i, dim in enumerate(x_dims):\n",
    "            x = tdist.multivariate_normal.MultivariateNormal(torch.zeros(dim), torch.eye(dim)).sample()\n",
    "            y_i = tdist.multivariate_normal.MultivariateNormal(all_Ws[i] @ z + all_Ls[i] @ x, all_Phis[i]).sample()\n",
    "            datasets[i] = torch.cat([datasets[i], y_i[None,:]])\n",
    "    datasets = [dataset[1:] for dataset in datasets]      \n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating sample: 999/1000\r"
     ]
    }
   ],
   "source": [
    "datasets = generate_samples(all_Ws, all_Ls, all_Phis, y_dims, x_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the y-vectors for each sample together\n",
    "y_concat = torch.cat(datasets, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have the low-rank structure and shit here\n",
    "def initialize_model(y_dims, x_dims, d=5, std=1e-2, mean=0):\n",
    "    Ws_to_stack = []\n",
    "    Phis_to_stack = []\n",
    "    Ls_to_stack = []\n",
    "    \n",
    "    for i, y_dim in enumerate(y_dims):\n",
    "        cur_W = torch.nn.init.normal_(torch.zeros(y_dim, d), mean=mean, std=std)\n",
    "        cur_L = torch.nn.init.normal_(torch.zeros(y_dim, x_dims[i]), mean=mean, std=std)\n",
    "        cur_Phi = torch.nn.init.normal_(torch.zeros(y_dim, y_dim), mean=mean, std=std)\n",
    "        Ws_to_stack.append(cur_W)\n",
    "        Ls_to_stack.append(cur_L)\n",
    "        Phis_to_stack.append(cur_Phi)\n",
    "    return torch.cat(Ws_to_stack, axis=0), torch.block_diag(*Ls_to_stack), torch.block_diag(*Phis_to_stack)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the ground-truth parameters\n",
    "W_GT = torch.cat(all_Ws, axis=0)\n",
    "L_GT = torch.block_diag(*all_Ls)\n",
    "Phi_GT = torch.block_diag(*all_Phis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the model parameters\n",
    "W_model, L_model, Phi_model = initialize_model(y_dims, x_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the E-Step required values (is there a way to batch this intelligently?)\n",
    "def E_step(W, L, Phi, x_dims, d, y_i):\n",
    "    # schur-complement (M/D)^{-1}\n",
    "    sigma_22_inv = torch.inverse(W@W.T + L @ L.T)\n",
    "\n",
    "    # other necessary block matrices\n",
    "    sigma_12 = torch.cat([W.T, L.T], axis=0)\n",
    "    sigma_11 = torch.eye(torch.sum(x_dims)+d)\n",
    "\n",
    "    # compute the posterior mean of z and x; y should be a matrix with all samples aligned as columns\n",
    "    posterior_z_x_mean = sigma_12 @ sigma_22_inv @ (y_i)\n",
    "    posterior_z_mean = posterior_z_x_mean[:d]\n",
    "    posterior_x_mean = posterior_z_x_mean[d:]\n",
    "\n",
    "    # posterior covariance\n",
    "    posterior_x1_cov = sigma_11 - sigma_12 @ sigma_22_inv @ sigma_12.T\n",
    "    posterior_z_x_cov = posterior_x1_cov[:d, d:]  # cross covariance\n",
    "    posterior_z_z_cov = posterior_x1_cov[:d, :d]  # upper left block matrix\n",
    "    posterior_x_x_cov = posterior_x1_cov[d:, d:]  # bottom right block matrix\n",
    "    \n",
    "    # need to batch zmu and xmu: [n_samples, <[z, x]>.shape, 1]\n",
    "    zmu_batched = posterior_z_mean.T[:, :, None]\n",
    "    xmu_batched = posterior_x_mean.T[:, :, None]\n",
    "\n",
    "    # posterior <zx.T> = cov(z, x) + <z><x.T>\n",
    "    posterior_zxT = posterior_z_x_cov + zmu_batched @ xmu_batched.permute(0, 2, 1)  # shape: (n_samples, z_dim, x_dim)\n",
    "    posterior_zzT = posterior_z_z_cov + zmu_batched @ zmu_batched.permute(0, 2, 1)  # shape: (n_samples, z_dim, z_dim)\n",
    "    posterior_xxT = posterior_x_x_cov + xmu_batched @ xmu_batched.permute(0, 2, 1)  # shape: (n_samples, x_dim, x_dim)\n",
    "\n",
    "    return posterior_zxT, posterior_zzT, posterior_xxT, zmu_batched, xmu_batched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1000])\n"
     ]
    }
   ],
   "source": [
    "y_concat_T = y_concat.T\n",
    "print(y_concat_T.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "zxT, zzT, xxT, zmu, xmu = E_step(W_model, L_model, Phi_model, x_dims, d, y_concat_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def M_step(zxT, zzT, xxT, zmu, xmu, y_i, Phi_model, L_model, W_model, N):\n",
    "    y_i_batched = y_i[:, :, None]  # (n_samples, batch_dim, 1)\n",
    "    new_L = torch.sum(y_i_batched @ xmu.permute(0, 2, 1) - W_model @ zxT, axis=0) @ torch.inverse(torch.sum(xxT, axis=0))\n",
    "    new_W = torch.sum(y_i_batched @ zmu.permute(0, 2, 1) - L_model @ zxT.permute(0, 2, 1), axis=0) @ torch.inverse(torch.sum(zzT, axis=0))\n",
    "    \n",
    "    phi_term_1 = 2 / N * torch.sum( (L_model @ xmu + W_model @ zmu) @ y_i_batched.permute(0, 2, 1), axis=0)\n",
    "    phi_term_2 = -1 / N * torch.sum(y_i_batched @ y_i_batched.permute(0, 2, 1), axis=0)\n",
    "    #     print(phi_term_1.shape)\n",
    "    #     print(phi_term_2.shape)\n",
    "    #     print(new_L.shape)\n",
    "    #     print(new_W.shape)\n",
    "    phi_term_3 = -1 / N * torch.sum( (L_model @ xxT @ L_model.T) + W_model @ zzT @ W_model.T + 2 * L_model @ zxT.permute(0, 2, 1) @ W_model.T, axis=0)\n",
    "    \n",
    "    new_Phi = torch.inverse(phi_term_1 + phi_term_2 + phi_term_3)\n",
    "    return new_W, new_L, new_Phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_W, new_L, new_Phi = M_step(zxT, zzT, xxT, zmu, xmu, y_concat, Phi_model, L_model, W_model, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2350/10000: W_mse: 3297.847900390625 Phi_mse: 0.08523043990135193 L_mse: 2912775.5.087e+18\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-137-abbbac50b8a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# E-Step, then M-Step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mzxT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzzT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxxT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxmu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mE_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPhi_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_concat_T\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mW_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPhi_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mM_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzxT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzzT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxxT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_concat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPhi_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# compute training stats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-128-e03004d9482d>\u001b[0m in \u001b[0;36mM_step\u001b[0;34m(zxT, zzT, xxT, zmu, xmu, y_i, Phi_model, L_model, W_model, N)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m#     print(new_L.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m#     print(new_W.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mphi_term_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mN\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mL_model\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mxxT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mL_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mW_model\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mzzT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mW_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mL_model\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mzxT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mW_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mnew_Phi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphi_term_1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mphi_term_2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mphi_term_3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# number of E/M-Steps To Run\n",
    "steps = 10000\n",
    "# initialize the model parameters\n",
    "W_model, L_model, Phi_model = initialize_model(y_dims, x_dims)\n",
    "\n",
    "# ground truth (GT) values\n",
    "W_GT = torch.cat(all_Ws, axis=0)\n",
    "L_GT = torch.block_diag(*all_Ls)\n",
    "Phi_GT = torch.block_diag(*all_Phis)\n",
    "\n",
    "# compute the reconstruction error\n",
    "W_losses = []\n",
    "L_losses = []\n",
    "Phi_losses = []\n",
    "\n",
    "# GPU setup\n",
    "# device = 'cpu'\n",
    "# if torch.cuda.is_available():\n",
    "#     device = 'cuda:0'\n",
    "\n",
    "# # move to the GPU    \n",
    "# W_model = W_model.to(device)\n",
    "# L_model = L_model.to(device)\n",
    "# Phi_model = Phi_model.to(device)\n",
    "# x_dims = x_dims.to(device)\n",
    "\n",
    "# iterate through E/M Steps\n",
    "for i in range(steps):\n",
    "    # E-Step, then M-Step\n",
    "    zxT, zzT, xxT, zmu, xmu = E_step(W_model, L_model, Phi_model, x_dims, d, y_concat_T)\n",
    "    W_model, L_model, Phi_model = M_step(zxT, zzT, xxT, zmu, xmu, y_concat, Phi_model, L_model, W_model, N)\n",
    "    \n",
    "    # compute training stats\n",
    "    W_mse = torch.mean(torch.pow(W_model - W_GT, 2))\n",
    "    L_mse = torch.mean(torch.pow(L_model - L_GT, 2))\n",
    "    Phi_mse = torch.mean(torch.pow(Phi_model - Phi_GT, 2))\n",
    "    \n",
    "    # store training stats\n",
    "    W_losses.append(W_mse.item())\n",
    "    L_losses.append(L_mse.item())\n",
    "    Phi_losses.append(Phi_mse.item())\n",
    "    \n",
    "    if (i % 50 == 0):\n",
    "        print(\"{}/{}: W_mse: {} Phi_mse: {} L_mse: {}\".format(i, steps, W_mse.item(), Phi_mse.item(), L_mse.item()), flush=True, end='\\r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
